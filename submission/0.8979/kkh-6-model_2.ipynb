{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“œ ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒ\n",
    "\n",
    "> - kimkihong / helpotcreator@gmail.com / Upstage AI Lab 3ê¸°\n",
    "> - 2024.07.30.í™” 10:00 ~ 2024.08.11.ì¼ 19:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from albumentations import ImageOnlyTransform\n",
    "from augraphy import *\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PRE_PATH = '/kkh/'\n",
    "TRAIN_KR_IMAGE_PATH = PRE_PATH + 'data/train_kr'\n",
    "TRAIN_KR_AUG_IMAGE_PATH = PRE_PATH + 'data/train_kr_aug'\n",
    "TEST_IMAGE_PATH = PRE_PATH + 'data/test'\n",
    "\n",
    "META_KR_CSV_PATH = PRE_PATH + 'data/meta_kr.csv'\n",
    "META_KR_DF = pd.read_csv(META_KR_CSV_PATH)\n",
    "TRAIN_KR_CSV_PATH = PRE_PATH + 'data/train_kr.csv'\n",
    "TRAIN_KR_DF = pd.read_csv(TRAIN_KR_CSV_PATH)\n",
    "TRAIN_KR_AUG_CSV_PATH = PRE_PATH + 'data/train_kr_aug.csv'\n",
    "TRAIN_KR_AUG_DF = pd.read_csv(TRAIN_KR_AUG_CSV_PATH)\n",
    "TEST_CSV_PATH = PRE_PATH + 'data/sample_submission.csv'\n",
    "TEST_DF = pd.read_csv(TEST_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, oversample=False):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.oversample = oversample\n",
    "\n",
    "        # í´ë˜ìŠ¤ê°„ ë¶ˆê· í˜• í•´ì†Œë¥¼ ìœ„í•œ ìƒ˜í”Œ ì¦ì‹\n",
    "        if self.oversample:\n",
    "            # ê° í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ìˆ˜ ê³„ì‚°\n",
    "            class_counts = np.bincount(self.df.values[:, 1].astype(int))\n",
    "\n",
    "            # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¦ì‹í•  íšŸìˆ˜ ì„¤ì • (ì´ ì˜ˆì œì—ì„œëŠ” ìµœëŒ€ ë°ì´í„° ìˆ˜ì— ë§ì¶¤)\n",
    "            max_class_count = max(class_counts)\n",
    "            oversample_factors = [max_class_count // count for count in class_counts]\n",
    "            # Class 3, 7 ê°€ì¤‘ì¹˜ 2ë¡œ ë³€ê²½\n",
    "            oversample_factors[3] = 2\n",
    "            oversample_factors[7] = 2 \n",
    "            # oversample_factors[14] = 3 \n",
    "\n",
    "            # ê° í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„°ë¥¼ ì¦ì‹í•œ ìƒˆë¡œìš´ ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "            oversampled_data = [self.df.values[self.df.values[:, 1] == cls].repeat(factor, axis=0) for cls, factor in enumerate(oversample_factors)]\n",
    "            oversampled_data = np.vstack(oversampled_data)\n",
    "\n",
    "            self.df = pd.DataFrame(oversampled_data, columns=self.df.columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df.iloc[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "    \n",
    "label_to_class_name = dict(zip(META_KR_DF['target'], META_KR_DF['class_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def training(model, dataloader, criterion, optimizer, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(dataloader)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {loss.item()}\")\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)    \n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return model, train_loss, train_acc, train_f1\n",
    "\n",
    "def evaluation(model, dataloader, criterion, device, epoch, num_epochs):\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    valid_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(dataloader)\n",
    "        for images, labels in tbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] - Valid Loss: {loss.item()}\")\n",
    "\n",
    "    valid_loss = valid_loss / len(dataloader)\n",
    "    valid_acc = accuracy_score(targets_list, preds_list)  \n",
    "    valid_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return valid_loss, valid_acc, valid_f1\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, criterion, optimizer, device, num_epochs, patience, model_name):\n",
    "    best_valid_loss = float('inf')  # ê°€ì¥ ì¢‹ì€ validation lossë¥¼ ì €ì¥\n",
    "    early_stop_counter = 0  # ì¹´ìš´í„°\n",
    "    valid_max_accuracy = -1\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_acc, train_f1 = training(model, train_dataloader, criterion, optimizer, device, epoch, num_epochs)\n",
    "        valid_loss, valid_acc, valid_f1 = evaluation(model, valid_dataloader, criterion, device, epoch, num_epochs)\n",
    "\n",
    "        # print(f'''Epoch [{epoch + 1}/{num_epochs}] Finished\n",
    "        # Train Loss: {train_loss:.4f}, Train Accu: {train_acc:.4f}, Train F1: {train_f1:.4f}\n",
    "        # Valid Loss: {valid_loss:.4f}, Valid Accu: {valid_acc:.4f}, Valid F1: {valid_f1:.4f}''')\n",
    "        print(f'''Epoch [{epoch + 1}/{num_epochs}] Finished\n",
    "        Valid Loss: {valid_loss:.4f}, Valid Accu: {valid_acc:.4f}, Valid F1: {valid_f1:.4f}''')\n",
    "\n",
    "        if valid_acc > valid_max_accuracy:\n",
    "          valid_max_accuracy = valid_acc\n",
    "\n",
    "        # validation lossê°€ ê°ì†Œí•˜ë©´ ëª¨ë¸ ì €ì¥ ë° ì¹´ìš´í„° ë¦¬ì…‹\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = model\n",
    "            torch.save(model.state_dict(), PRE_PATH + f\"{model_name}_{valid_loss:.4f}_{valid_f1:.4f}.pt\")\n",
    "            early_stop_counter = 0\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]  Model Saved')\n",
    "            print(f'=========================================================================================================')\n",
    "\n",
    "        else: early_stop_counter += 1\n",
    "        if early_stop_counter >= patience: break\n",
    "    return best_model, valid_max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ plottingì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def normalize_image(image):\n",
    "    # ì´ë¯¸ì§€ë¥¼ [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    normalized_image = (image - image_min) / (image_max - image_min)\n",
    "    return normalized_image\n",
    "\n",
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "    \n",
    "    num_rows = n_images // 3  # í–‰ì˜ ê°œìˆ˜ ê³„ì‚°\n",
    "    if n_images % 3 != 0:\n",
    "        num_rows += 1    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(30, 10 * num_rows))\n",
    "\n",
    "    for i in range(n_images):\n",
    "        image = images[i]\n",
    "        label = classes[labels[i]]\n",
    "        row_idx = i // 3\n",
    "        col_idx = i % 3\n",
    "        \n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "        \n",
    "        axes[row_idx, col_idx].imshow(image.permute(1, 2, 0))\n",
    "        axes[row_idx, col_idx].set_title(label)\n",
    "        axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# validation config\n",
    "VALID_RATIO = 0.8\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b4'\n",
    "pretrained_size = 380\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "# training config\n",
    "LR = 5e-4\n",
    "BATCH_SIZE = 32\n",
    "dropout_ratio = 0.2\n",
    "patience = 5\n",
    "num_workers = 0\n",
    "num_classes = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "train_transform = A.Compose([\n",
    "    # PatternGeneratorTransform(pattern, p=0.3), # íŒ¨í„´ ë…¸ì´ì¦ˆ\n",
    "    # A.Resize(height=pretrained_size, width=pretrained_size), # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
    "    # ì´ë¯¸ì§€ ê¸´ ì¸¡ë©´ í¬ê¸° ì¡°ì ˆ í›„ íŒ¨ë”© ì ìš©\n",
    "    A.LongestMaxSize(max_size=pretrained_size, always_apply=True), \n",
    "    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n",
    "    \n",
    "    A.Normalize(mean=pretrained_means, std=pretrained_stds), # images normalization\n",
    "    ToTensorV2() # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "])\n",
    "\n",
    "# test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ\n",
    "test_transform = A.Compose([    \n",
    "    # A.Resize(height=pretrained_size, width=pretrained_size),\n",
    "    A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n",
    "    \n",
    "    A.Normalize(mean=pretrained_means, std=pretrained_stds),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# aug_test_transform = A.Compose([    \n",
    "#     A.RandomRotate90(),\n",
    "#     A.Flip(p=0.5),              \n",
    "                        \n",
    "#     # A.Resize(height=pretrained_size, width=pretrained_size),\n",
    "#     A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n",
    "#     A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n",
    "    \n",
    "#     A.Normalize(mean=pretrained_means, std=pretrained_stds),\n",
    "#     ToTensorV2()\n",
    "# ])\n",
    "\n",
    "# ì‹œê°í™”ë¥¼ ìœ„í•œ transform ì½”ë“œ\n",
    "base_transform = A.Compose([\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44808 3140\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset ì •ì˜\n",
    "train_dataset = ImageDataset(\n",
    "    TRAIN_KR_AUG_CSV_PATH,\n",
    "    TRAIN_KR_AUG_IMAGE_PATH,\n",
    "    transform=train_transform,\n",
    "    oversample=True\n",
    ")\n",
    "\n",
    "# Test Dataset ì •ì˜\n",
    "test_dataset = ImageDataset(\n",
    "    TEST_CSV_PATH,\n",
    "    TEST_IMAGE_PATH,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# aug_test_dataset = ImageDataset(\n",
    "#     data_path + 'sample_submission.csv',\n",
    "#     data_path + 'test/',\n",
    "#     transform=aug_test_transform\n",
    "# )\n",
    "\n",
    "# ì‹œê°í™”ìš© Dataset ì •ì˜\n",
    "train_dataset_v = ImageDataset(\n",
    "    TRAIN_KR_AUG_CSV_PATH,\n",
    "    TRAIN_KR_AUG_IMAGE_PATH,\n",
    "    transform=base_transform\n",
    ")\n",
    "\n",
    "test_dataset_v = ImageDataset(\n",
    "    TEST_CSV_PATH,\n",
    "    TEST_IMAGE_PATH,\n",
    "    transform=base_transform\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset ê°œìˆ˜: 35846\n",
      "Validation dataset ê°œìˆ˜: 8962\n",
      "Test dataset ê°œìˆ˜: 3140\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì…‹ì„ í•™ìŠµ ë°ì´í„° ì…‹ê³¼ ê²€ì¦ ë°ì´í„° ì…‹ìœ¼ë¡œ ë¶„ë¦¬\n",
    "total_size = len(train_dataset)\n",
    "train_num, valid_num = int(total_size * VALID_RATIO), total_size - int(total_size * VALID_RATIO)\n",
    "\n",
    "# train - valid set ë‚˜ëˆ„ê¸°\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num], generator = generator)\n",
    "\n",
    "valid_data = copy.deepcopy(valid_dataset)\n",
    "valid_data.dataset.transform = test_transform\n",
    "\n",
    "print(f'Train dataset ê°œìˆ˜: {len(train_dataset)}')\n",
    "print(f'Validation dataset ê°œìˆ˜: {len(valid_dataset)}')\n",
    "print(f'Test dataset ê°œìˆ˜: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader ì •ì˜\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    "    )\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    "    )\n",
    "\n",
    "# aug_test_dataloader = DataLoader(\n",
    "#     aug_test_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "#     pin_memory=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€í™˜ëœ í•™ìŠµ ì´ë¯¸ì§€ í™•ì¸\n",
    "N_IMAGES = 24\n",
    "\n",
    "# ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±\n",
    "selected_indices = random.sample(range(len(train_dataset_v)), N_IMAGES)\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in [train_dataset_v[i] for i in selected_indices]])\n",
    "# images, labels = zip(*[(image, label) for image, label in [train_dataset_v[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "# plot_images(images, labels, label_to_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "class CustomEfficientNetB4(nn.Module):\n",
    "    def __init__(self, num_classes, attention_size=1792):\n",
    "        super(CustomEfficientNetB4, self).__init__()\n",
    "        self.base_model = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "        \n",
    "        # Remove the existing classifier\n",
    "        self.base_model.reset_classifier(0, '')\n",
    "\n",
    "        # Add attention mechanism\n",
    "        self.attention = AttentionModule(attention_size, attention_size)\n",
    "\n",
    "        # New classifier with attention\n",
    "        self.classifier = nn.Linear(attention_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.mean([2, 3])\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # Final classification\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b4.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b4.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "model = CustomEfficientNetB4(num_classes).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Loss: 0.005107571836560965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:31<00:00,  2.48it/s] \n",
      "Epoch [1/50] - Valid Loss: 8.821413757686969e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:48<00:00,  5.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Finished\n",
      "        Valid Loss: 0.0212, Valid Accu: 0.9921, Valid F1: 0.9945\n",
      "Epoch [1/50]  Model Saved\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Train Loss: 0.001251098234206438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:28<00:00,  2.50it/s]  \n",
      "Epoch [2/50] - Valid Loss: 1.7881390590446244e-07: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:49<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Finished\n",
      "        Valid Loss: 0.0071, Valid Accu: 0.9977, Valid F1: 0.9983\n",
      "Epoch [2/50]  Model Saved\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] - Train Loss: 0.0003154269070364535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:28<00:00,  2.50it/s] \n",
      "Epoch [3/50] - Valid Loss: 5.960461066933931e-07: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:49<00:00,  5.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Finished\n",
      "        Valid Loss: 0.0170, Valid Accu: 0.9950, Valid F1: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Train Loss: 0.24753506481647491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:29<00:00,  2.50it/s]   \n",
      "Epoch [4/50] - Valid Loss: 5.900824817217654e-06: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:48<00:00,  5.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Finished\n",
      "        Valid Loss: 0.0050, Valid Accu: 0.9987, Valid F1: 0.9987\n",
      "Epoch [4/50]  Model Saved\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - Train Loss: 2.9065891794743948e-05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:29<00:00,  2.49it/s]\n",
      "Epoch [5/50] - Valid Loss: 0.01642776094377041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:48<00:00,  5.82it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Finished\n",
      "        Valid Loss: 0.0262, Valid Accu: 0.9926, Valid F1: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] - Train Loss: 0.00048690548283047974: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:30<00:00,  2.49it/s]\n",
      "Epoch [6/50] - Valid Loss: 0.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:49<00:00,  5.65it/s]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Finished\n",
      "        Valid Loss: 0.0030, Valid Accu: 0.9989, Valid F1: 0.9991\n",
      "Epoch [6/50]  Model Saved\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] - Train Loss: 0.002182930475100875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:29<00:00,  2.50it/s]  \n",
      "Epoch [7/50] - Valid Loss: 3.5762775496550603e-07: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:48<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Finished\n",
      "        Valid Loss: 0.0012, Valid Accu: 0.9993, Valid F1: 0.9993\n",
      "Epoch [7/50]  Model Saved\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] - Train Loss: 0.004544389899820089: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:30<00:00,  2.49it/s]  \n",
      "Epoch [8/50] - Valid Loss: 0.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:49<00:00,  5.71it/s]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Finished\n",
      "        Valid Loss: 0.0017, Valid Accu: 0.9997, Valid F1: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] - Train Loss: 0.01921486295759678: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1121/1121 [07:32<00:00,  2.48it/s]   \n",
      "Epoch [9/50] - Valid Loss: 0.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281/281 [00:48<00:00,  5.77it/s]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Finished\n",
      "        Valid Loss: 0.0083, Valid Accu: 0.9973, Valid F1: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] - Train Loss: 0.0007015187875367701:   4%|â–         | 48/1121 [00:19<07:18,  2.45it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ë° ê²€ì¦ ìµœëŒ€ ì •í™•ë„ ì¶œë ¥\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model, valid_max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# í•™ìŠµí•  ëª¨ë¸\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# í›ˆë ¨ ë°ì´í„°ë¡œë”\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ê²€ì¦ ë°ì´í„°ë¡œë”\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# ì†ì‹¤ í•¨ìˆ˜\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ì˜µí‹°ë§ˆì´ì €\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# ë””ë°”ì´ìŠ¤ (CPU ë˜ëŠ” GPU)\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# ì´ ì—í­ ìˆ˜\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# ì¡°ê¸° ì¤‘ë‹¨ì„ ìœ„í•œ ì¸ë‚´ ìˆ˜\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ëª¨ë¸ ì´ë¦„\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ê²€ì¦ ë°ì´í„°ì—ì„œì˜ ìµœëŒ€ ì •í™•ë„ ì¶œë ¥\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Max Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_max_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 66\u001b[0m     model, train_loss, train_acc, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     valid_loss, valid_acc, valid_f1 \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, criterion, device, epoch, num_epochs)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# print(f'''Epoch [{epoch + 1}/{num_epochs}] Finished\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Train Loss: {train_loss:.4f}, Train Accu: {train_acc:.4f}, Train F1: {train_f1:.4f}\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Valid Loss: {valid_loss:.4f}, Valid Accu: {valid_acc:.4f}, Valid F1: {valid_f1:.4f}''')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     22\u001b[0m targets_list\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ë° ê²€ì¦ ìµœëŒ€ ì •í™•ë„ ì¶œë ¥\n",
    "model, valid_max_accuracy = training_loop(\n",
    "    model,             # í•™ìŠµí•  ëª¨ë¸\n",
    "    train_dataloader,  # í›ˆë ¨ ë°ì´í„°ë¡œë”\n",
    "    valid_dataloader,  # ê²€ì¦ ë°ì´í„°ë¡œë”\n",
    "    loss_fn,           # ì†ì‹¤ í•¨ìˆ˜\n",
    "    optimizer,         # ì˜µí‹°ë§ˆì´ì €\n",
    "    device,            # ë””ë°”ì´ìŠ¤ (CPU ë˜ëŠ” GPU)\n",
    "    EPOCHS,            # ì´ ì—í­ ìˆ˜\n",
    "    patience,          # ì¡°ê¸° ì¤‘ë‹¨ì„ ìœ„í•œ ì¸ë‚´ ìˆ˜\n",
    "    model_name         # ëª¨ë¸ ì´ë¦„\n",
    ")\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì—ì„œì˜ ìµœëŒ€ ì •í™•ë„ ì¶œë ¥\n",
    "print(f'Valid Max Accuracy: {valid_max_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:17<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions: [2, 12, 5, 13, 2, 15, 0, 8, 15, 11, 5, 7, 16, 9, 15, 4, 7, 5, 13, 10, 12, 12, 1, 6, 3, 0, 14, 16, 1, 6, 3, 0, 13, 2, 5, 16, 13, 7, 15, 0, 5, 9, 12, 9, 0, 8, 5, 0, 11, 14, 10, 10, 10, 6, 4, 12, 9, 5, 13, 13, 12, 4, 5, 5, 6, 1, 5, 7, 10, 6, 7, 10, 8, 15, 7, 15, 6, 12, 12, 13, 8, 9, 9, 14, 10, 10, 5, 13, 10, 0, 10, 8, 5, 15, 7, 16, 11, 11, 7, 11, 14, 7, 13, 1, 15, 11, 2, 12, 16, 8, 6, 2, 0, 4, 12, 16, 2, 7, 11, 4, 2, 6, 5, 8, 10, 6, 4, 4, 7, 6, 5, 7, 15, 10, 16, 16, 3, 6, 6, 8, 4, 8, 14, 2, 12, 8, 3, 5, 3, 8, 6, 8, 16, 12, 11, 16, 9, 15, 6, 8, 5, 5, 10, 10, 16, 15, 9, 12, 16, 5, 2, 8, 8, 16, 9, 8, 16, 16, 3, 4, 11, 15, 9, 9, 2, 7, 11, 10, 9, 0, 4, 0, 16, 5, 14, 15, 5, 12, 0, 4, 13, 2, 6, 16, 16, 10, 8, 9, 0, 10, 5, 1, 14, 4, 11, 2, 0, 3, 0, 13, 7, 0, 16, 7, 12, 5, 3, 0, 14, 6, 0, 7, 12, 12, 9, 6, 9, 10, 9, 15, 10, 14, 9, 11, 12, 0, 1, 11, 12, 6, 7, 15, 4, 7, 14, 15, 4, 12, 7, 4, 0, 15, 13, 11, 6, 12, 8, 7, 9, 0, 8, 7, 4, 5, 0, 0, 14, 0, 9, 12, 1, 7, 7, 8, 12, 7, 15, 9, 15, 15, 9, 4, 8, 7, 15, 1, 9, 4, 8, 11, 14, 11, 6, 5, 13, 16, 13, 15, 5, 9, 7, 6, 2, 16, 7, 7, 3, 15, 8, 15, 13, 15, 11, 6, 2, 12, 16, 6, 5, 9, 16, 11, 16, 0, 16, 9, 15, 10, 6, 6, 1, 4, 1, 5, 5, 14, 4, 13, 3, 1, 16, 10, 4, 7, 5, 3, 12, 7, 3, 6, 4, 3, 7, 10, 7, 7, 12, 10, 5, 9, 15, 13, 11, 6, 9, 1, 8, 3, 4, 16, 6, 0, 6, 3, 16, 10, 4, 9, 0, 13, 9, 2, 13, 12, 8, 7, 0, 2, 4, 12, 16, 0, 15, 16, 9, 12, 11, 3, 5, 8, 16, 14, 10, 2, 6, 16, 7, 7, 11, 11, 10, 5, 13, 10, 6, 11, 5, 7, 4, 9, 4, 3, 8, 9, 7, 8, 11, 16, 14, 5, 16, 11, 3, 1, 0, 12, 0, 0, 9, 11, 15, 7, 7, 2, 11, 7, 6, 11, 7, 2, 7, 4, 6, 2, 9, 2, 9, 2, 10, 5, 6, 6, 15, 4, 8, 0, 16, 10, 9, 15, 10, 6, 0, 8, 13, 3, 15, 6, 10, 10, 11, 4, 16, 3, 3, 6, 9, 10, 8, 16, 6, 7, 12, 0, 7, 0, 7, 8, 6, 11, 13, 2, 8, 6, 15, 13, 7, 15, 10, 16, 11, 8, 7, 0, 15, 4, 1, 2, 13, 5, 0, 4, 9, 16, 3, 0, 4, 10, 3, 14, 11, 6, 2, 12, 12, 15, 11, 3, 5, 2, 13, 16, 13, 15, 5, 2, 8, 11, 2, 7, 15, 9, 14, 10, 9, 9, 13, 10, 12, 15, 7, 14, 7, 9, 8, 16, 7, 5, 6, 3, 7, 4, 2, 5, 8, 1, 7, 3, 15, 11, 3, 3, 13, 9, 3, 11, 6, 9, 2, 0, 5, 15, 7, 10, 7, 6, 2, 6, 7, 0, 6, 2, 5, 13, 4, 3, 5, 10, 16, 15, 5, 12, 11, 7, 6, 4, 8, 16, 16, 3, 10, 0, 15, 3, 7, 7, 4, 4, 8, 12, 7, 12, 11, 3, 14, 12, 2, 7, 2, 6, 14, 10, 16, 5, 16, 2, 12, 16, 9, 10, 16, 16, 15, 12, 10, 9, 4, 2, 11, 4, 13, 16, 4, 7, 9, 0, 7, 7, 11, 4, 6, 3, 0, 9, 3, 16, 7, 2, 15, 3, 12, 1, 13, 16, 5, 2, 13, 3, 2, 15, 8, 11, 6, 6, 14, 5, 0, 2, 7, 6, 0, 4, 7, 6, 5, 8, 4, 2, 3, 14, 10, 4, 16, 2, 3, 1, 5, 12, 10, 9, 0, 6, 2, 5, 13, 11, 9, 4, 9, 5, 4, 8, 7, 13, 16, 5, 11, 14, 3, 12, 15, 1, 12, 5, 15, 5, 3, 8, 10, 11, 9, 4, 7, 3, 4, 9, 6, 9, 8, 16, 4, 1, 16, 4, 13, 5, 6, 3, 10, 6, 4, 16, 8, 8, 11, 10, 8, 8, 8, 7, 0, 12, 3, 12, 7, 9, 14, 2, 2, 3, 5, 1, 12, 2, 4, 7, 9, 4, 3, 9, 0, 13, 12, 6, 7, 8, 6, 13, 14, 6, 3, 2, 15, 15, 8, 3, 3, 12, 13, 13, 5, 4, 8, 12, 3, 13, 16, 6, 10, 6, 1, 16, 8, 3, 7, 4, 15, 1, 4, 9, 11, 10, 4, 8, 10, 16, 9, 15, 15, 7, 12, 11, 0, 0, 10, 14, 2, 8, 11, 16, 16, 1, 7, 9, 15, 11, 5, 15, 2, 0, 10, 11, 15, 1, 8, 11, 16, 11, 9, 8, 4, 1, 12, 10, 9, 3, 12, 7, 2, 15, 12, 11, 6, 12, 14, 13, 16, 16, 5, 8, 1, 11, 9, 12, 6, 15, 4, 8, 9, 16, 3, 6, 14, 10, 11, 16, 0, 13, 14, 14, 11, 6, 3, 7, 9, 0, 5, 11, 14, 13, 8, 12, 0, 2, 2, 7, 7, 15, 9, 4, 4, 8, 9, 9, 15, 4, 7, 7, 2, 0, 3, 16, 11, 15, 6, 4, 2, 16, 2, 14, 0, 10, 8, 11, 10, 16, 5, 6, 0, 6, 9, 5, 15, 16, 10, 4, 16, 11, 7, 13, 10, 9, 4, 6, 3, 0, 9, 7, 15, 1, 2, 8, 1, 12, 13, 3, 15, 6, 11, 7, 2, 9, 9, 2, 7, 8, 2, 11, 7, 5, 15, 6, 14, 16, 13, 4, 6, 14, 9, 3, 6, 10, 13, 0, 13, 7, 3, 11, 9, 8, 0, 13, 5, 13, 1, 0, 7, 12, 8, 14, 2, 14, 6, 15, 0, 6, 0, 16, 16, 5, 0, 3, 12, 5, 7, 1, 3, 7, 4, 7, 6, 4, 12, 12, 0, 8, 5, 10, 9, 13, 15, 5, 12, 1, 6, 13, 13, 15, 1, 8, 0, 9, 2, 16, 4, 7, 2, 6, 13, 7, 15, 7, 12, 7, 11, 2, 10, 10, 3, 15, 2, 12, 16, 6, 0, 2, 11, 12, 5, 16, 2, 5, 7, 16, 6, 14, 3, 16, 2, 3, 11, 2, 0, 7, 2, 4, 7, 8, 0, 0, 12, 6, 12, 0, 7, 1, 11, 8, 2, 15, 8, 0, 10, 15, 9, 12, 0, 5, 9, 8, 13, 9, 4, 1, 4, 16, 10, 1, 9, 0, 9, 9, 4, 13, 9, 10, 8, 13, 11, 0, 5, 2, 5, 3, 9, 1, 8, 11, 4, 2, 9, 4, 6, 11, 12, 14, 8, 1, 10, 11, 2, 15, 2, 12, 5, 15, 2, 14, 9, 10, 1, 3, 9, 3, 13, 16, 12, 8, 15, 8, 5, 16, 3, 12, 8, 11, 8, 0, 7, 6, 11, 2, 4, 11, 11, 5, 7, 6, 7, 10, 0, 14, 4, 10, 9, 12, 6, 13, 13, 6, 11, 0, 7, 6, 2, 11, 12, 9, 3, 6, 15, 8, 4, 4, 7, 14, 14, 11, 15, 5, 3, 13, 3, 12, 10, 16, 6, 8, 12, 5, 9, 5, 13, 0, 11, 11, 15, 2, 15, 16, 7, 3, 0, 15, 16, 0, 11, 5, 12, 10, 15, 12, 5, 7, 3, 5, 16, 2, 15, 11, 4, 8, 3, 12, 9, 16, 9, 7, 5, 6, 1, 8, 3, 3, 10, 7, 6, 10, 3, 15, 12, 6, 8, 13, 8, 15, 14, 2, 4, 1, 16, 13, 10, 13, 5, 7, 9, 11, 4, 12, 0, 11, 3, 16, 13, 0, 0, 15, 15, 7, 4, 0, 8, 4, 7, 2, 15, 5, 5, 12, 2, 3, 2, 8, 8, 4, 6, 12, 8, 6, 1, 8, 7, 10, 4, 9, 3, 5, 4, 16, 10, 4, 7, 9, 6, 7, 4, 9, 5, 2, 2, 15, 6, 10, 11, 9, 2, 5, 12, 3, 11, 15, 11, 9, 8, 11, 12, 13, 1, 16, 10, 15, 2, 16, 0, 9, 7, 5, 5, 11, 9, 4, 4, 4, 2, 7, 7, 16, 7, 9, 11, 9, 16, 4, 2, 0, 11, 8, 5, 7, 5, 10, 15, 8, 9, 0, 6, 4, 0, 15, 11, 1, 0, 7, 5, 12, 6, 12, 7, 10, 15, 2, 7, 7, 9, 13, 13, 2, 6, 9, 16, 9, 1, 9, 9, 1, 15, 6, 14, 15, 6, 4, 10, 11, 16, 11, 9, 2, 3, 10, 3, 8, 9, 10, 4, 12, 11, 1, 7, 16, 0, 5, 6, 6, 3, 3, 2, 10, 4, 7, 2, 16, 9, 12, 1, 0, 0, 6, 13, 7, 12, 10, 16, 10, 3, 4, 7, 4, 8, 0, 3, 15, 15, 7, 8, 4, 5, 6, 12, 10, 11, 5, 4, 15, 12, 8, 7, 5, 8, 0, 3, 4, 0, 15, 11, 13, 13, 13, 4, 6, 4, 11, 8, 15, 3, 15, 9, 6, 7, 0, 15, 3, 8, 5, 13, 5, 0, 13, 2, 12, 8, 13, 10, 4, 14, 13, 4, 10, 3, 11, 15, 12, 1, 5, 12, 7, 7, 8, 7, 2, 4, 5, 15, 6, 12, 8, 4, 10, 12, 16, 11, 8, 7, 13, 3, 11, 13, 5, 9, 8, 16, 6, 15, 12, 13, 4, 16, 2, 13, 14, 11, 3, 12, 4, 15, 0, 6, 10, 7, 9, 16, 2, 0, 13, 9, 7, 0, 5, 0, 4, 0, 4, 12, 11, 2, 7, 3, 5, 13, 5, 6, 4, 4, 10, 9, 8, 16, 9, 6, 12, 5, 9, 14, 7, 12, 14, 15, 15, 7, 3, 8, 15, 2, 3, 2, 16, 6, 12, 9, 0, 2, 15, 5, 9, 6, 16, 7, 5, 5, 15, 5, 15, 7, 9, 7, 6, 8, 8, 10, 14, 10, 14, 1, 10, 15, 1, 7, 13, 6, 11, 2, 4, 13, 2, 10, 2, 11, 10, 12, 9, 4, 3, 6, 2, 15, 7, 16, 6, 8, 10, 1, 0, 16, 4, 3, 8, 0, 2, 0, 16, 16, 12, 2, 8, 7, 9, 16, 5, 0, 6, 14, 16, 8, 10, 1, 5, 6, 13, 7, 4, 3, 8, 3, 11, 16, 12, 10, 7, 10, 16, 2, 6, 0, 3, 0, 2, 8, 7, 2, 16, 11, 7, 13, 12, 13, 12, 11, 16, 16, 5, 10, 15, 8, 16, 7, 5, 15, 10, 3, 1, 12, 9, 7, 13, 9, 7, 6, 6, 10, 6, 16, 7, 4, 6, 14, 16, 11, 7, 9, 16, 3, 10, 6, 11, 1, 0, 9, 3, 2, 13, 12, 15, 16, 0, 15, 6, 11, 7, 0, 7, 11, 13, 8, 0, 9, 14, 5, 2, 15, 10, 2, 9, 16, 15, 9, 16, 6, 4, 9, 6, 16, 6, 7, 9, 0, 6, 15, 7, 1, 6, 16, 16, 7, 6, 2, 2, 10, 14, 14, 3, 0, 1, 10, 15, 5, 11, 1, 16, 7, 4, 9, 4, 0, 9, 14, 10, 16, 16, 16, 0, 7, 11, 9, 5, 9, 11, 0, 5, 7, 5, 16, 14, 15, 16, 3, 10, 14, 15, 4, 16, 12, 2, 11, 10, 11, 7, 12, 6, 12, 15, 12, 4, 10, 16, 2, 2, 3, 8, 7, 10, 7, 15, 11, 12, 13, 3, 3, 11, 7, 13, 11, 6, 0, 12, 15, 10, 10, 6, 4, 12, 2, 6, 15, 5, 13, 6, 10, 6, 8, 15, 16, 3, 3, 9, 3, 7, 16, 15, 5, 3, 13, 10, 14, 9, 5, 16, 2, 2, 11, 5, 16, 11, 2, 9, 10, 4, 1, 11, 2, 10, 13, 11, 16, 1, 3, 4, 2, 11, 1, 4, 8, 13, 12, 3, 6, 15, 4, 15, 13, 10, 1, 5, 8, 6, 0, 7, 10, 8, 7, 0, 11, 13, 12, 1, 11, 11, 5, 4, 6, 16, 9, 4, 10, 0, 0, 8, 6, 9, 0, 11, 5, 12, 2, 15, 15, 10, 6, 15, 16, 4, 15, 6, 11, 13, 16, 5, 14, 2, 1, 11, 15, 7, 13, 11, 1, 10, 3, 8, 13, 16, 5, 10, 10, 2, 6, 0, 13, 3, 12, 5, 9, 4, 12, 12, 13, 4, 8, 0, 8, 4, 2, 15, 3, 16, 16, 15, 4, 5, 3, 13, 10, 15, 10, 16, 9, 3, 13, 9, 7, 11, 12, 7, 0, 2, 11, 15, 4, 6, 6, 11, 2, 2, 14, 12, 6, 8, 12, 0, 12, 3, 16, 7, 4, 3, 4, 12, 10, 0, 10, 12, 0, 5, 8, 6, 13, 8, 11, 1, 10, 10, 6, 13, 4, 16, 16, 3, 7, 14, 10, 12, 3, 15, 6, 10, 10, 2, 5, 16, 5, 10, 5, 8, 12, 0, 13, 4, 12, 12, 15, 15, 10, 16, 6, 0, 10, 7, 5, 11, 4, 6, 5, 16, 4, 9, 5, 10, 6, 1, 5, 9, 4, 3, 5, 13, 4, 2, 7, 6, 10, 8, 7, 13, 0, 6, 11, 16, 10, 2, 6, 12, 6, 10, 0, 0, 9, 10, 6, 0, 11, 4, 6, 4, 7, 12, 3, 15, 15, 8, 9, 13, 7, 1, 6, 13, 6, 9, 1, 13, 5, 8, 7, 13, 16, 6, 6, 15, 3, 6, 7, 10, 10, 16, 1, 15, 2, 13, 2, 12, 2, 8, 12, 0, 4, 1, 16, 9, 11, 10, 2, 3, 3, 10, 3, 5, 15, 7, 7, 4, 12, 1, 8, 6, 14, 14, 12, 16, 6, 4, 10, 6, 0, 7, 10, 0, 7, 7, 13, 12, 12, 10, 2, 16, 8, 7, 12, 11, 11, 8, 14, 4, 0, 2, 12, 6, 11, 8, 13, 1, 4, 9, 2, 4, 11, 2, 8, 3, 11, 16, 15, 16, 14, 5, 12, 4, 8, 5, 14, 5, 3, 10, 15, 11, 12, 6, 9, 5, 12, 16, 16, 14, 11, 15, 9, 12, 0, 9, 2, 2, 11, 15, 5, 13, 2, 6, 11, 2, 1, 3, 4, 11, 16, 13, 8, 0, 2, 2, 11, 7, 14, 12, 3, 16, 10, 8, 2, 0, 16, 4, 2, 7, 11, 3, 16, 5, 15, 9, 15, 6, 16, 16, 15, 0, 7, 10, 0, 7, 8, 2, 12, 3, 2, 4, 6, 15, 8, 2, 13, 3, 10, 6, 16, 9, 7, 8, 8, 13, 6, 3, 0, 7, 9, 3, 4, 0, 16, 7, 12, 4, 5, 13, 13, 11, 13, 11, 10, 3, 4, 4, 1, 16, 5, 0, 8, 15, 3, 6, 2, 4, 7, 6, 11, 16, 0, 16, 2, 11, 1, 8, 10, 7, 0, 7, 6, 10, 10, 4, 6, 9, 13, 9, 12, 8, 7, 8, 6, 8, 16, 2, 6, 0, 5, 1, 16, 9, 4, 15, 5, 5, 7, 13, 7, 12, 4, 2, 11, 15, 14, 3, 5, 0, 5, 3, 11, 7, 2, 16, 13, 5, 16, 9, 14, 10, 16, 9, 5, 9, 0, 4, 7, 12, 13, 13, 7, 5, 16, 6, 13, 12, 2, 12, 9, 5, 7, 4, 12, 2, 10, 8, 15, 6, 15, 6, 16, 12, 7, 6, 4, 13, 0, 3, 1, 6, 0, 0, 8, 8, 10, 12, 8, 15, 4, 2, 5, 0, 5, 10, 8, 15, 8, 9, 8, 11, 10, 3, 9, 5, 10, 15, 4, 11, 0, 14, 0, 5, 11, 0, 5, 13, 14, 11, 16, 15, 15, 7, 0, 7, 5, 14, 1, 11, 11, 13, 13, 0, 5, 3, 2, 0, 4, 2, 10, 8, 7, 7, 8, 8, 15, 6, 8, 10, 9, 2, 9, 4, 7, 5, 5, 11, 0, 11, 12, 10, 7, 7, 9, 15, 4, 15, 6, 7, 0, 15, 15, 12, 4, 5, 7, 10, 8, 14, 0, 13, 6, 5, 8, 5, 10, 6, 12, 8, 12, 7, 9, 10, 11, 6, 6, 0, 0, 8, 13, 8, 10, 8, 4, 16, 7, 5, 7, 10, 2, 8, 1, 1, 15, 3, 0, 8, 6, 10, 6, 16, 12, 2, 15, 5, 8, 15, 5, 9, 0, 4, 2, 0, 11, 5, 0, 7, 3, 0, 4, 9, 11, 15, 10, 2, 10, 12, 5, 5, 13, 5, 16, 15, 7, 7, 5, 16, 5, 9, 11, 11, 4, 5, 5, 4, 9, 8, 6, 11, 4, 11, 10, 0, 11, 7, 11, 15, 10, 5, 15, 16, 8, 5, 3, 7, 4, 2, 4, 12, 6, 7, 15, 1, 15, 0, 8, 7, 6, 10, 15, 4, 6, 9, 8, 4, 14, 12, 8, 7, 16, 13, 5, 5, 15, 9, 8, 16, 9, 16, 0, 12, 6, 3, 6, 6, 9, 13, 10, 2, 0, 12, 0, 0, 11, 5, 8, 8, 16, 2, 16, 1, 6, 14, 4, 14, 9, 7, 1, 12, 4, 8, 3, 2, 5, 4, 4, 16, 8, 2, 7, 15, 13, 9, 4, 8, 12, 15, 7, 6, 8, 16, 16, 16, 15, 2, 5, 9, 10, 13, 6, 9, 4, 0, 10, 15, 16, 6, 9, 2, 14, 13, 12, 1, 3, 4, 3, 16, 12, 8, 11, 5, 15, 6, 11, 12, 0, 16, 5, 11, 5, 7, 8, 11, 3, 8, 7, 9, 13, 15, 11, 9, 7, 7, 6, 1, 0, 11, 12, 2, 4, 4, 5, 3, 3, 7, 10, 12, 14, 10, 4, 6, 13, 15, 6, 2, 8, 13, 4, 8, 3, 0, 11, 13, 14, 9, 16, 2, 10, 15, 0, 4, 1, 11, 6, 4, 4, 8, 1, 12, 14, 12, 11, 13, 0, 13, 2, 15, 15, 15, 4, 11, 6, 6, 7, 8, 15, 8, 2, 3, 8, 9, 9, 7, 4, 0, 2, 12, 16, 5, 15, 8, 15, 12, 11, 10, 6, 7, 2, 0, 3, 4, 3, 10, 11, 0, 9, 7, 10, 15, 2, 7, 2, 0, 15, 0, 2, 6, 16, 5, 2, 10, 3, 5, 13, 14, 1, 12, 12, 8, 5, 7, 16, 12, 11, 5, 14, 11, 13, 3, 13, 7, 2, 2, 0, 7, 0, 0, 4, 5, 13, 4, 10, 7, 12, 7, 10, 15, 10, 0, 3, 0, 14, 7, 5, 16, 2, 7, 15, 2, 4, 10, 5, 6, 10, 8, 16, 9, 15, 8, 15, 0, 3, 1, 16, 7, 6, 8, 12, 14, 12, 15, 9, 3, 4, 10, 15, 4, 9, 4, 6, 11, 3, 11, 2, 6, 10, 8, 0, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(f'/kkh/efficientnet_b4_0.0012_0.9993.pt'))\n",
    "# model.load_state_dict(torch.load(f'/kkh/efficientnet_b4_0.0030_0.9991.pt'))\n",
    "# model.load_state_dict(torch.load(f'/kkh/efficientnet_b4_0.0050_0.9987.pt'))\n",
    "# model.load_state_dict(torch.load(f'/kkh/efficientnet_b4_0.0071_0.9983.pt'))\n",
    "model.load_state_dict(torch.load(f'/kkh/efficientnet_b4_0.0212_0.9945.pt'))\n",
    "# model.load_state_dict(torch.load(PRE_PATH + f'model_{model_name}.pt'))\n",
    "model.to(device)\n",
    "\n",
    "N_TTA = 20\n",
    "preds_list = []\n",
    "with torch.no_grad():\n",
    "    # loaders = [test_dataloader] + [aug_test_dataloader] * N_TTA\n",
    "    loaders = [test_dataloader]\n",
    "\n",
    "    for batches in tqdm(zip(*loaders), total=len(test_dataloader)):\n",
    "        images, *aug_images = [images.to(device) for images, _ in batches]\n",
    "\n",
    "        outputs_original = model(images)\n",
    "        outputs_augmented = [model(aug_image) for aug_image in aug_images]\n",
    "\n",
    "        final_outputs = (outputs_original + sum(outputs_augmented)) / N_TTA + 1\n",
    "        preds_list.extend(final_outputs.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸\n",
    "print(\"Ensemble Predictions:\", preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "\n",
    "assert (TEST_DF['ID'] == pred_df['ID']).all()\n",
    "\n",
    "# pred_df.to_csv(\"/kkh/submission/efficientnet_b4_0.0012_0.9993.csv\", index=False)\n",
    "# pred_df.to_csv(\"/kkh/submission/efficientnet_b4_0.0030_0.9991.csv\", index=False)\n",
    "# pred_df.to_csv(\"/kkh/submission/efficientnet_b4_0.0050_0.9987.csv\", index=False)\n",
    "# pred_df.to_csv(\"/kkh/submission/efficientnet_b4_0.0071_0.9983.csv\", index=False)\n",
    "pred_df.to_csv(\"/kkh/submission/efficientnet_b4_0.0212_0.9945.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
