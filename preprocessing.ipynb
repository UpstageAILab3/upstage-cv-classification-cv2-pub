{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 0\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Transformation: flip_horizontal, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    # Convert the image to PIL format\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # Perform OCR on the image\n",
    "    ocr_result = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT)\n",
    "    # Calculate the readability score based on the number of characters detected\n",
    "    num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "    return num_chars\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    transformations = {\n",
    "        \"original\": img,\n",
    "        \"rot90\": cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"rot180\": cv2.rotate(img, cv2.ROTATE_180),\n",
    "        \"rot270\": cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        \"flip_horizontal\": cv2.flip(img, 1),\n",
    "        \"flip_horizontal_rot90\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"flip_horizontal_rot180\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_180),\n",
    "        \"flip_horizontal_rot270\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "best_img = find_best_orientation('dj/data/test/0a4f2decf34d3bff.jpg')\n",
    "cv2.imwrite('dj/best_oriented_image.jpg', best_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 0\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Transformation: flip_horizontal, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        # Perform OCR on the image\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT)\n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    transformations = {\n",
    "        \"original\": img,\n",
    "        \"rot90\": cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"rot180\": cv2.rotate(img, cv2.ROTATE_180),\n",
    "        \"rot270\": cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        \"flip_horizontal\": cv2.flip(img, 1),\n",
    "        \"flip_horizontal_rot90\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"flip_horizontal_rot180\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_180),\n",
    "        \"flip_horizontal_rot270\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 0\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Transformation: flip_horizontal, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Denoise using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    transformations = {\n",
    "        \"original\": img,\n",
    "        \"rot90\": cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"rot180\": cv2.rotate(img, cv2.ROTATE_180),\n",
    "        \"rot270\": cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        \"flip_horizontal\": cv2.flip(img, 1),\n",
    "        \"flip_horizontal_rot90\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"flip_horizontal_rot180\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_180),\n",
    "        \"flip_horizontal_rot270\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: original, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 490\n",
      "Transformation: rot90, Readability Score: 550\n",
      "Transformation: rot180, Readability Score: 486\n",
      "Transformation: rot270, Readability Score: 535\n",
      "Transformation: flip_horizontal, Readability Score: 471\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 498\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 533\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 509\n",
      "Best transformation: rot90 with score: 550\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    transformations = {\n",
    "        \"original\": img,\n",
    "        \"rot90\": cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"rot180\": cv2.rotate(img, cv2.ROTATE_180),\n",
    "        \"rot270\": cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        \"flip_horizontal\": cv2.flip(img, 1),\n",
    "        \"flip_horizontal_rot90\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"flip_horizontal_rot180\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_180),\n",
    "        \"flip_horizontal_rot270\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 490\n",
      "Transformation: rot90, Readability Score: 550\n",
      "Transformation: rot180, Readability Score: 486\n",
      "Transformation: rot270, Readability Score: 535\n",
      "Transformation: flip_horizontal, Readability Score: 471\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 498\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 533\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 509\n",
      "Best transformation: rot90 with score: 550\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def detect_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Apply transformations\n",
    "    transformations = {\n",
    "        \"original\": img,\n",
    "        \"rot90\": cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"rot180\": cv2.rotate(img, cv2.ROTATE_180),\n",
    "        \"rot270\": cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        \"flip_horizontal\": cv2.flip(img, 1),\n",
    "        \"flip_horizontal_rot90\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_CLOCKWISE),\n",
    "        \"flip_horizontal_rot180\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_180),\n",
    "        \"flip_horizontal_rot270\": cv2.rotate(cv2.flip(img, 1), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    }\n",
    "\n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = detect_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: rot0, Readability Score: 490\n",
      "Transformation: rot15, Readability Score: 455\n",
      "Transformation: rot30, Readability Score: 335\n",
      "Transformation: rot45, Readability Score: 312\n",
      "Transformation: rot60, Readability Score: 259\n",
      "Transformation: rot75, Readability Score: 275\n",
      "Transformation: rot90, Readability Score: 349\n",
      "Transformation: rot105, Readability Score: 292\n",
      "Transformation: rot120, Readability Score: 334\n",
      "Transformation: rot135, Readability Score: 267\n",
      "Transformation: rot150, Readability Score: 294\n",
      "Transformation: rot165, Readability Score: 393\n",
      "Transformation: rot180, Readability Score: 486\n",
      "Transformation: rot195, Readability Score: 484\n",
      "Transformation: rot210, Readability Score: 357\n",
      "Transformation: rot225, Readability Score: 330\n",
      "Transformation: rot240, Readability Score: 302\n",
      "Transformation: rot255, Readability Score: 308\n",
      "Transformation: rot270, Readability Score: 378\n",
      "Transformation: rot285, Readability Score: 354\n",
      "Transformation: rot300, Readability Score: 350\n",
      "Transformation: rot315, Readability Score: 276\n",
      "Transformation: rot330, Readability Score: 320\n",
      "Transformation: rot345, Readability Score: 465\n",
      "Transformation: flip_horizontal, Readability Score: 471\n",
      "Best transformation: rot0 with score: 490\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot345, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_vertical_rot345, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_both_rot345, Readability Score: 0\n",
      "Best transformation: original with score: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'original'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     80\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj/data/test/0a4f2decf34d3bff.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 81\u001b[0m best_img \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_orientation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj/best_oriented_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[37], line 77\u001b[0m, in \u001b[0;36mfind_best_orientation\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m         best_transformation \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest transformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_transformation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_transformation\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\n",
    "    \n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    transformations.update({f\"flip_vertical_rot{angle}\": rotate_image(cv2.flip(img, 0), angle) for angle in angles})\n",
    "    transformations.update({f\"flip_both_rot{angle}\": rotate_image(cv2.flip(cv2.flip(img, 1), 0), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot15, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot30, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot45, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot60, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot75, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot105, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot120, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot135, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot150, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot165, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot195, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot210, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot225, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot240, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot255, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot285, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot300, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot315, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot330, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: rot345, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 0\n",
      "Error in OCR processing: [Errno 2] Unable to synchronously open file (unable to open file: name = 'esrgan_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 0\n",
      "Best transformation: original with score: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'original'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     96\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj/data/test/0a4f2decf34d3bff.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 97\u001b[0m best_img \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_orientation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj/best_oriented_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 93\u001b[0m, in \u001b[0;36mfind_best_orientation\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m         best_transformation \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest transformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_transformation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_transformation\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: rot0, Readability Score: 434\n",
      "Transformation: rot15, Readability Score: 330\n",
      "Transformation: rot30, Readability Score: 221\n",
      "Transformation: rot45, Readability Score: 365\n",
      "Transformation: rot60, Readability Score: 330\n",
      "Transformation: rot75, Readability Score: 312\n",
      "Transformation: rot90, Readability Score: 349\n",
      "Transformation: rot105, Readability Score: 337\n",
      "Transformation: rot120, Readability Score: 290\n",
      "Transformation: rot135, Readability Score: 318\n",
      "Transformation: rot150, Readability Score: 219\n",
      "Transformation: rot165, Readability Score: 245\n",
      "Transformation: rot180, Readability Score: 401\n",
      "Transformation: rot195, Readability Score: 247\n",
      "Transformation: rot210, Readability Score: 222\n",
      "Transformation: rot225, Readability Score: 374\n",
      "Transformation: rot240, Readability Score: 200\n",
      "Transformation: rot255, Readability Score: 317\n",
      "Transformation: rot270, Readability Score: 303\n",
      "Transformation: rot285, Readability Score: 258\n",
      "Transformation: rot300, Readability Score: 222\n",
      "Transformation: rot315, Readability Score: 280\n",
      "Transformation: rot330, Readability Score: 296\n",
      "Transformation: rot345, Readability Score: 318\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 401\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 236\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 277\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 303\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 366\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 254\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 341\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 385\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 239\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 254\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 262\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 295\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 468\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 295\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 246\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 298\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 297\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 349\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 289\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 290\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 297\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 282\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 249\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 252\n",
      "Best transformation: flip_horizontal_rot180 with score: 468\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\n",
    "    \n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot345, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/eng.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'eng\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 0\n",
      "Best transformation: original with score: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'original'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     90\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dj/data/test/0a5bf6ba56f069c5.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 91\u001b[0m best_img \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_orientation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdj/best_oriented_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[34], line 87\u001b[0m, in \u001b[0;36mfind_best_orientation\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     84\u001b[0m         best_transformation \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest transformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_transformation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_transformation\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\n",
    "    \n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = '/dj/data/test/0a5bf6ba56f069c5.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: original, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot345, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the TESSDATA_PREFIX environment variable\n",
    "os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/'\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration for Korean\n",
    "        custom_config = r'--oem 3 --psm 6 -l kor'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\n",
    "    \n",
    "    transformations = {\"original\": img}\n",
    "    transformations.update({f\"rot{angle}\": rotate_image(img, angle) for angle in angles})\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations[best_transformation]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: original, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Error in OCR processing: (1, 'Error opening data file /usr/share/tesseract-ocr/4.00/kor.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'kor\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the TESSDATA_PREFIX environment variable\n",
    "os.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/'\n",
    "\n",
    "# Specify the path to the Tesseract executable if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Adjust the path as needed\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert the image to PIL format\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        \n",
    "        # Perform OCR on the image with additional configuration for Korean\n",
    "        custom_config = r'--oem 3 --psm 6 -l kor'\n",
    "        ocr_result = pytesseract.image_to_data(pil_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Calculate the readability score based on the number of characters detected\n",
    "        num_chars = sum(len(word) for word in ocr_result['text'] if word.strip())\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 90, 180, 270]\n",
    "    transformations = {\"original\": img}\n",
    "    transformations.update({f\"rot{angle}\": rotate_image(img, angle) for angle in angles})\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.1% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cv/lib/python3.10/site-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/conda/envs/cv/lib/python3.10/site-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 0\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['ko'], gpu=False)  # 'ko' is the language code for Korean\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        result = reader.readtext(preprocessed_image)\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = sum(len(text[1]) for text in result)\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 90, 180, 270]\n",
    "    transformations = {\"original\": img}\n",
    "    transformations.update({f\"rot{angle}\": rotate_image(img, angle) for angle in angles})\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: original, Readability Score: 0\n",
      "Transformation: rot0, Readability Score: 0\n",
      "Transformation: rot90, Readability Score: 0\n",
      "Transformation: rot180, Readability Score: 0\n",
      "Transformation: rot270, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 0\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: original with score: 0\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['ko'], gpu=False)  # 'ko' is the language code for Korean\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding (binarization)\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Sharpen the image to enhance edges\n",
    "    sharpen_kernel = np.array([[-1, -1, -1], \n",
    "                               [-1, 9, -1], \n",
    "                               [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n",
    "    \n",
    "    return sharpened\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        result = reader.readtext(preprocessed_image)\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = sum(len(text[1]) for text in result)\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 90, 180, 270]\n",
    "    transformations = {\"original\": img}\n",
    "    transformations.update({f\"rot{angle}\": rotate_image(img, angle) for angle in angles})\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/Multilingual_PP-OCRv3_det_infer.tar to /data/ephemeral/home/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer/Multilingual_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.85M/3.85M [00:03<00:00, 1.10MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/multilingual/korean_PP-OCRv4_rec_infer.tar to /data/ephemeral/home/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer/korean_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24.4M/24.4M [00:03<00:00, 6.40MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /data/ephemeral/home/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.19M/2.19M [00:16<00:00, 130kiB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/08/01 11:41:50] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/data/ephemeral/home/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/data/ephemeral/home/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/opt/conda/envs/cv/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/korean_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/data/ephemeral/home/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='korean', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/08/01 11:41:52] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.29978370666503906\n",
      "[2024/08/01 11:41:52] ppocr DEBUG: cls num  : 8, elapsed : 0.10980653762817383\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: rec_res num  : 8, elapsed : 0.6940979957580566\n",
      "Transformation: original, Readability Score: 5\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.1017310619354248\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: cls num  : 8, elapsed : 0.010725736618041992\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: rec_res num  : 8, elapsed : 0.4693927764892578\n",
      "Transformation: rot0, Readability Score: 5\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.09248590469360352\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 11:41:53] ppocr DEBUG: rec_res num  : 0, elapsed : 1.430511474609375e-06\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot90, Readability Score: 0\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.044309139251708984\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: cls num  : 6, elapsed : 0.04902935028076172\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: rec_res num  : 6, elapsed : 0.2933166027069092\n",
      "Transformation: rot180, Readability Score: 10\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.09120821952819824\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: cls num  : 2, elapsed : 0.0055620670318603516\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: rec_res num  : 2, elapsed : 0.1111290454864502\n",
      "Transformation: rot270, Readability Score: 1\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.10485982894897461\n",
      "[2024/08/01 11:41:54] ppocr DEBUG: cls num  : 5, elapsed : 0.081329345703125\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: rec_res num  : 5, elapsed : 0.3920285701751709\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 2\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.10072588920593262\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: cls num  : 2, elapsed : 0.004904508590698242\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: rec_res num  : 2, elapsed : 0.18685245513916016\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 1\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.10449385643005371\n",
      "[2024/08/01 11:41:55] ppocr DEBUG: cls num  : 3, elapsed : 0.09317874908447266\n",
      "[2024/08/01 11:41:56] ppocr DEBUG: rec_res num  : 3, elapsed : 0.30400824546813965\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 1\n",
      "[2024/08/01 11:41:56] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.09830617904663086\n",
      "[2024/08/01 11:41:56] ppocr DEBUG: cls num  : 1, elapsed : 0.08930826187133789\n",
      "[2024/08/01 11:41:56] ppocr DEBUG: rec_res num  : 1, elapsed : 0.28561973571777344\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "Best transformation: rot180 with score: 10\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the PaddleOCR reader\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='korean')  # 'korean' is the language code for Korean\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding (binarization)\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Sharpen the image to enhance edges\n",
    "    sharpen_kernel = np.array([[-1, -1, -1], \n",
    "                               [-1, 9, -1], \n",
    "                               [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n",
    "    \n",
    "    return sharpened\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        result = ocr.ocr(preprocessed_image, cls=True)\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = sum(len(line[1][0]) for line in result[0])\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = [0, 90, 180, 270]\n",
    "    transformations = {\"original\": img}\n",
    "    transformations.update({f\"rot{angle}\": rotate_image(img, angle) for angle in angles})\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/08/01 14:03:32] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/data/ephemeral/home/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/data/ephemeral/home/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/opt/conda/envs/cv/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/korean_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/data/ephemeral/home/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='korean', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/08/01 14:03:34] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.1905813217163086\n",
      "[2024/08/01 14:03:34] ppocr DEBUG: cls num  : 8, elapsed : 0.18923711776733398\n",
      "[2024/08/01 14:03:35] ppocr DEBUG: rec_res num  : 8, elapsed : 0.691007137298584\n",
      "Transformation: rot0, Readability Score: 6\n",
      "[2024/08/01 14:03:35] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.11631083488464355\n",
      "[2024/08/01 14:03:35] ppocr DEBUG: cls num  : 7, elapsed : 0.02646803855895996\n",
      "[2024/08/01 14:03:36] ppocr DEBUG: rec_res num  : 7, elapsed : 0.5791270732879639\n",
      "Transformation: rot15, Readability Score: 2\n",
      "[2024/08/01 14:03:36] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.07509016990661621\n",
      "[2024/08/01 14:03:36] ppocr DEBUG: cls num  : 7, elapsed : 0.08877110481262207\n",
      "[2024/08/01 14:03:36] ppocr DEBUG: rec_res num  : 7, elapsed : 0.4011092185974121\n",
      "Transformation: rot30, Readability Score: 2\n",
      "[2024/08/01 14:03:37] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.04267454147338867\n",
      "[2024/08/01 14:03:37] ppocr DEBUG: cls num  : 4, elapsed : 0.08980059623718262\n",
      "[2024/08/01 14:03:37] ppocr DEBUG: rec_res num  : 4, elapsed : 0.3968782424926758\n",
      "Transformation: rot45, Readability Score: 1\n",
      "[2024/08/01 14:03:37] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04278302192687988\n",
      "[2024/08/01 14:03:37] ppocr DEBUG: cls num  : 2, elapsed : 0.03499245643615723\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: rec_res num  : 2, elapsed : 0.11782288551330566\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot60, Readability Score: 0\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.037253618240356445\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: cls num  : 1, elapsed : 0.005326509475708008\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1539444923400879\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot75, Readability Score: 0\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.04059147834777832\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: cls num  : 1, elapsed : 0.005498170852661133\n",
      "[2024/08/01 14:03:38] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1818711757659912\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot90, Readability Score: 0\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.039185523986816406\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot105, Readability Score: 0\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.04353523254394531\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot120, Readability Score: 0\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06934309005737305\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: cls num  : 1, elapsed : 0.005814313888549805\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10575342178344727\n",
      "Transformation: rot135, Readability Score: 2\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.0348203182220459\n",
      "[2024/08/01 14:03:39] ppocr DEBUG: cls num  : 6, elapsed : 0.03238272666931152\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: rec_res num  : 6, elapsed : 0.21454286575317383\n",
      "Transformation: rot150, Readability Score: 9\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.05974531173706055\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: rec_res num  : 0, elapsed : 1.430511474609375e-06\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot165, Readability Score: 0\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.04354047775268555\n",
      "[2024/08/01 14:03:40] ppocr DEBUG: cls num  : 7, elapsed : 0.011636734008789062\n",
      "[2024/08/01 14:03:41] ppocr DEBUG: rec_res num  : 7, elapsed : 0.46244120597839355\n",
      "Transformation: rot180, Readability Score: 8\n",
      "[2024/08/01 14:03:41] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.0663442611694336\n",
      "[2024/08/01 14:03:41] ppocr DEBUG: cls num  : 5, elapsed : 0.019896745681762695\n",
      "[2024/08/01 14:03:41] ppocr DEBUG: rec_res num  : 5, elapsed : 0.39301133155822754\n",
      "Transformation: rot195, Readability Score: 5\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.03707599639892578\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: cls num  : 1, elapsed : 0.07833409309387207\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10817480087280273\n",
      "Transformation: rot210, Readability Score: 1\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.05370354652404785\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: cls num  : 3, elapsed : 0.022888898849487305\n",
      "[2024/08/01 14:03:42] ppocr DEBUG: rec_res num  : 3, elapsed : 0.2951619625091553\n",
      "Transformation: rot225, Readability Score: 1\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.047028303146362305\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: cls num  : 8, elapsed : 0.08305096626281738\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: rec_res num  : 8, elapsed : 0.40902137756347656\n",
      "Transformation: rot240, Readability Score: 5\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04039788246154785\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: cls num  : 2, elapsed : 0.006232738494873047\n",
      "[2024/08/01 14:03:43] ppocr DEBUG: rec_res num  : 2, elapsed : 0.19110774993896484\n",
      "Transformation: rot255, Readability Score: 2\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.039719343185424805\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: cls num  : 3, elapsed : 0.009961605072021484\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: rec_res num  : 3, elapsed : 0.2720487117767334\n",
      "Transformation: rot270, Readability Score: 1\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04195690155029297\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: cls num  : 2, elapsed : 0.006352663040161133\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: rec_res num  : 2, elapsed : 0.11475419998168945\n",
      "Transformation: rot285, Readability Score: 3\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.03740549087524414\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:44] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: rot300, Readability Score: 0\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.03435993194580078\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: cls num  : 1, elapsed : 0.005201816558837891\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: rec_res num  : 1, elapsed : 0.17858338356018066\n",
      "Transformation: rot315, Readability Score: 2\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.04291892051696777\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: cls num  : 4, elapsed : 0.008010387420654297\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: rec_res num  : 4, elapsed : 0.20021295547485352\n",
      "Transformation: rot330, Readability Score: 1\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.05533933639526367\n",
      "[2024/08/01 14:03:45] ppocr DEBUG: cls num  : 8, elapsed : 0.012102842330932617\n",
      "[2024/08/01 14:03:46] ppocr DEBUG: rec_res num  : 8, elapsed : 0.4946451187133789\n",
      "Transformation: rot345, Readability Score: 4\n",
      "[2024/08/01 14:03:46] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.04113960266113281\n",
      "[2024/08/01 14:03:46] ppocr DEBUG: cls num  : 8, elapsed : 0.014084339141845703\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: rec_res num  : 8, elapsed : 0.4121522903442383\n",
      "Transformation: original, Readability Score: 6\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.04135894775390625\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: cls num  : 5, elapsed : 0.04675745964050293\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: rec_res num  : 5, elapsed : 0.2992877960205078\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot0, Readability Score: 0\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.036084890365600586\n",
      "[2024/08/01 14:03:47] ppocr DEBUG: cls num  : 3, elapsed : 0.009325027465820312\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: rec_res num  : 3, elapsed : 0.1977684497833252\n",
      "Transformation: flip_horizontal_rot15, Readability Score: 4\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.03592991828918457\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: cls num  : 3, elapsed : 0.07256364822387695\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: rec_res num  : 3, elapsed : 0.20633888244628906\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot30, Readability Score: 0\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.033121347427368164\n",
      "[2024/08/01 14:03:48] ppocr DEBUG: cls num  : 1, elapsed : 0.061579227447509766\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10811519622802734\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot45, Readability Score: 0\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.03378939628601074\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: cls num  : 1, elapsed : 0.04416537284851074\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10440635681152344\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot60, Readability Score: 0\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.053742408752441406\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: rec_res num  : 0, elapsed : 1.1920928955078125e-06\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot75, Readability Score: 0\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.05632781982421875\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: cls num  : 2, elapsed : 0.005558013916015625\n",
      "[2024/08/01 14:03:49] ppocr DEBUG: rec_res num  : 2, elapsed : 0.1911451816558838\n",
      "Transformation: flip_horizontal_rot90, Readability Score: 2\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06576895713806152\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: cls num  : 1, elapsed : 0.005817413330078125\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: rec_res num  : 1, elapsed : 0.11015915870666504\n",
      "Transformation: flip_horizontal_rot105, Readability Score: 3\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.03798341751098633\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: cls num  : 1, elapsed : 0.02823805809020996\n",
      "[2024/08/01 14:03:50] ppocr DEBUG: rec_res num  : 1, elapsed : 0.11592984199523926\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot120, Readability Score: 0\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.05424857139587402\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: cls num  : 1, elapsed : 0.005585193634033203\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1884174346923828\n",
      "Transformation: flip_horizontal_rot135, Readability Score: 1\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.03896450996398926\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: cls num  : 3, elapsed : 0.08091235160827637\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: rec_res num  : 3, elapsed : 0.20644283294677734\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot150, Readability Score: 0\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04990839958190918\n",
      "[2024/08/01 14:03:51] ppocr DEBUG: cls num  : 2, elapsed : 0.007055044174194336\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: rec_res num  : 2, elapsed : 0.18659591674804688\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot165, Readability Score: 0\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.12461733818054199\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: cls num  : 4, elapsed : 0.0060732364654541016\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: rec_res num  : 4, elapsed : 0.1975395679473877\n",
      "Transformation: flip_horizontal_rot180, Readability Score: 1\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.08226752281188965\n",
      "[2024/08/01 14:03:52] ppocr DEBUG: cls num  : 4, elapsed : 0.006197452545166016\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: rec_res num  : 4, elapsed : 0.2026221752166748\n",
      "Transformation: flip_horizontal_rot195, Readability Score: 1\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.0596003532409668\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: cls num  : 4, elapsed : 0.007280111312866211\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: rec_res num  : 4, elapsed : 0.2797675132751465\n",
      "Transformation: flip_horizontal_rot210, Readability Score: 1\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.03396964073181152\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: rec_res num  : 0, elapsed : 1.430511474609375e-06\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot225, Readability Score: 0\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.03534126281738281\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/08/01 14:03:53] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot240, Readability Score: 0\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04444003105163574\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: cls num  : 2, elapsed : 0.05963706970214844\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: rec_res num  : 2, elapsed : 0.11713457107543945\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot255, Readability Score: 0\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.043894290924072266\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: cls num  : 1, elapsed : 0.05588126182556152\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10822582244873047\n",
      "Error in OCR processing: 'NoneType' object is not iterable\n",
      "Transformation: flip_horizontal_rot270, Readability Score: 0\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.04209542274475098\n",
      "[2024/08/01 14:03:54] ppocr DEBUG: cls num  : 5, elapsed : 0.01017451286315918\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: rec_res num  : 5, elapsed : 0.2977738380432129\n",
      "Transformation: flip_horizontal_rot285, Readability Score: 7\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.042083740234375\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: cls num  : 2, elapsed : 0.00599217414855957\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: rec_res num  : 2, elapsed : 0.11682724952697754\n",
      "Transformation: flip_horizontal_rot300, Readability Score: 1\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.04511260986328125\n",
      "[2024/08/01 14:03:55] ppocr DEBUG: cls num  : 5, elapsed : 0.05806303024291992\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: rec_res num  : 5, elapsed : 0.300351619720459\n",
      "Transformation: flip_horizontal_rot315, Readability Score: 1\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.06016826629638672\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: cls num  : 2, elapsed : 0.0050776004791259766\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: rec_res num  : 2, elapsed : 0.18328547477722168\n",
      "Transformation: flip_horizontal_rot330, Readability Score: 1\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.06719779968261719\n",
      "[2024/08/01 14:03:56] ppocr DEBUG: cls num  : 10, elapsed : 0.013424396514892578\n",
      "[2024/08/01 14:03:57] ppocr DEBUG: rec_res num  : 10, elapsed : 0.49608302116394043\n",
      "Transformation: flip_horizontal_rot345, Readability Score: 6\n",
      "Best transformation: rot150 with score: 9\n",
      "Best oriented image saved to dj/best_oriented_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the PaddleOCR reader\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='korean')  # 'korean' is the language code for Korean\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding (binarization)\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    denoised = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Sharpen the image to enhance edges\n",
    "    sharpen_kernel = np.array([[-1, -1, -1], \n",
    "                               [-1, 9, -1], \n",
    "                               [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n",
    "    \n",
    "    # Further denoising\n",
    "    denoised = cv2.fastNlMeansDenoising(sharpened, None, 30, 7, 21)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        result = ocr.ocr(preprocessed_image, cls=True)\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = sum(len(line[1][0]) for line in result[0])\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Get the image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Calculate the center of the image\n",
    "    center = (w // 2, h // 2)\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = list(range(0, 360, 15))  # Rotate every 15 degrees\n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations[\"original\"] = img\n",
    "    \n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(cv2.flip(img, 1), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = '/dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    cv2.imwrite(output_path, best_img)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool: duplicate file name sentencepiece_model.proto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DonutProcessor, VisionEncoderDecoderModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the pre-trained Donut model and processor\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mDonutProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnaver-clova-ix/donut-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m VisionEncoderDecoderModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnaver-clova-ix/donut-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Resize and convert image to RGB\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/processing_utils.py:183\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Instantiate a processor associated with a pretrained model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/processing_utils.py:227\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 227\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:641\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m         )\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1801\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1799\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1956\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;66;03m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1956\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1961\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:155\u001b[0m, in \u001b[0;36mXLMRobertaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    141\u001b[0m     vocab_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m ):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Mask token behave like a normal word, i.e. include the space before it\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     mask_token \u001b[38;5;241m=\u001b[39m AddedToken(mask_token, lstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_token, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask_token\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_save_slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:118\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# We need to create and convert a slow tokenizer to build the backend\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_tokenizer_class(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslow_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1162\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn instance of tokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be converted in a Fast tokenizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m No converter was found. Currently available slow->fast convertors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1158\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m converter_class \u001b[38;5;241m=\u001b[39m SLOW_TO_FAST_CONVERTERS[tokenizer_class_name]\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverter_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconverted()\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:438\u001b[0m, in \u001b[0;36mSpmConverter.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    434\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotobuf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sentencepiece_model_pb2 \u001b[38;5;28;01mas\u001b[39;00m model_pb2\n\u001b[1;32m    440\u001b[0m m \u001b[38;5;241m=\u001b[39m model_pb2\u001b[38;5;241m.\u001b[39mModelProto()\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/utils/sentencepiece_model_pb2.py:29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 29\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentencepiece_model.proto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentencepiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msyntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproto2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;130;43;01m\\003\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_create_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_pb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x19\u001b[39;49;00m\u001b[38;5;124;43msentencepiece_model.proto\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43msentencepiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xa1\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43mTrainerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43minput_format\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mmodel_prefix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x41\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m$.sentencepiece.TrainerSpec.ModelType:\u001b[39;49m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNIGRAM\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mvocab_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x38\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mpt_language\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x15\u001b[39;49;00m\u001b[38;5;124;43mself_test_sample_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;124;43mharacter_coverage\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m.9995\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43minput_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mshuffle_input_sentence\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43mmining_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mtraining_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43mseed_sentencepiece_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43mshrinking_factor\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m.75\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43mmax_sentence_length\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x34\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x39\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43mnum_threads\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43mnum_sub_iterations\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43mmax_sentencepiece_length\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43msplit_by_unicode_script\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x15\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43msplit_by_number\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43msplit_by_whitespace\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43mtreat_whitespace_as_suffix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43msplit_digits\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x19\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;124;43montrol_symbols\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43muser_defined_symbols\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1f\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mrequired_chars\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mbyte_fallback\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m# \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43mvocabulary_output_piece_score\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m  \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43mhard_vocab_limit\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m! \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43muse_all_vocab\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43munk_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m( \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x62\u001b[39;49;00m\u001b[38;5;124;43mos_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mos_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m* \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mpad_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m-1\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43munk_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m- \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mbos_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m<s>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43meos_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m/ \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m</s>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mpad_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m<pad>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43munk_surface\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\xe2\u001b[39;49;00m\u001b[38;5;130;43;01m\\x81\u001b[39;49;00m\u001b[38;5;130;43;01m\\x87\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;124;43mtrain_extremely_large_corpus\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mModelType\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNIGRAM\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;124;43mPE\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mWORD\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x43\u001b[39;49;00m\u001b[38;5;124;43mHAR\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xd1\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mNormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43mprecompiled_charsmap\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;124;43m_dummy_prefix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m&\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43mremove_extra_whitespaces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mscape_whitespaces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mnormalization_rule_tsv\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mSelfTestData\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x33\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.sentencepiece.SelfTestData.Sample\u001b[39;49m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mSample\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mxpected\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xfe\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mModelProto\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x37\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mpieces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.sentencepiece.ModelProto.SentencePiece\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mtrainer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.TrainerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43mnormalizer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.NormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x33\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mself_test_data\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1b\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.SelfTestData\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x38\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mnormalizer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.NormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;130;43;01m\\xd2\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mSentencePiece\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m,.sentencepiece.ModelProto.SentencePiece.Type:\u001b[39;49m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mNORMAL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mNORMAL\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNKNOWN\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\x43\u001b[39;49;00m\u001b[38;5;124;43mONTROL\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mUSER_DEFINED\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;124;43mYTE\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mUNUSED\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m _TRAINERSPEC_MODELTYPE \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[1;32m     86\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentencepiece.TrainerSpec.ModelType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1347\u001b[39m,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m _sym_db\u001b[38;5;241m.\u001b[39mRegisterEnumDescriptor(_TRAINERSPEC_MODELTYPE)\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/google/protobuf/descriptor.py:1072\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool: duplicate file name sentencepiece_model.proto"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Load the pre-trained Donut model and processor\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize and convert image to RGB\n",
    "    resized_image = image.resize((1000, 1000)).convert(\"RGB\")\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Prepare the image for Donut\n",
    "        pixel_values = processor(preprocessed_image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Perform OCR using Donut\n",
    "        generated_ids = model.generate(pixel_values, max_length=512)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = len(generated_text)\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Rotate the image by the specified angle\n",
    "    return image.rotate(angle, expand=True)\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = list(range(0, 360, 15))  # Rotate every 15 degrees\n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations[\"original\"] = img\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(img.transpose(Image.FLIP_LEFT_RIGHT), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    best_img.save(output_path)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool: duplicate file name sentencepiece_model.proto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DonutProcessor, VisionEncoderDecoderModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the pre-trained Donut model and processor\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mDonutProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnaver-clova-ix/donut-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m VisionEncoderDecoderModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnaver-clova-ix/donut-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Resize and convert image to RGB\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/processing_utils.py:183\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Instantiate a processor associated with a pretrained model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/processing_utils.py:227\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 227\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:641\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m         )\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1801\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1799\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1956\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;66;03m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1956\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1961\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py:155\u001b[0m, in \u001b[0;36mXLMRobertaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, bos_token, eos_token, sep_token, cls_token, unk_token, pad_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    141\u001b[0m     vocab_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m ):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Mask token behave like a normal word, i.e. include the space before it\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     mask_token \u001b[38;5;241m=\u001b[39m AddedToken(mask_token, lstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rstrip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_token, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask_token\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_save_slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:118\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# We need to create and convert a slow tokenizer to build the backend\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_tokenizer_class(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslow_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1162\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn instance of tokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be converted in a Fast tokenizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m No converter was found. Currently available slow->fast convertors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1158\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m converter_class \u001b[38;5;241m=\u001b[39m SLOW_TO_FAST_CONVERTERS[tokenizer_class_name]\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverter_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconverted()\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:438\u001b[0m, in \u001b[0;36mSpmConverter.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    434\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotobuf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sentencepiece_model_pb2 \u001b[38;5;28;01mas\u001b[39;00m model_pb2\n\u001b[1;32m    440\u001b[0m m \u001b[38;5;241m=\u001b[39m model_pb2\u001b[38;5;241m.\u001b[39mModelProto()\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/transformers/utils/sentencepiece_model_pb2.py:29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m---> 29\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentencepiece_model.proto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentencepiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msyntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproto2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;130;43;01m\\003\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_create_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_pb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x19\u001b[39;49;00m\u001b[38;5;124;43msentencepiece_model.proto\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43msentencepiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xa1\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43mTrainerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43minput_format\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mmodel_prefix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x41\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m$.sentencepiece.TrainerSpec.ModelType:\u001b[39;49m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNIGRAM\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mvocab_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x38\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mpt_language\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x15\u001b[39;49;00m\u001b[38;5;124;43mself_test_sample_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;124;43mharacter_coverage\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m.9995\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43minput_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mshuffle_input_sentence\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43mmining_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mtraining_sentence_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43mseed_sentencepiece_size\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43mshrinking_factor\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m.75\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43mmax_sentence_length\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x34\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x39\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43mnum_threads\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43mnum_sub_iterations\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43mmax_sentencepiece_length\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43msplit_by_unicode_script\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x15\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43msplit_by_number\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x13\u001b[39;49;00m\u001b[38;5;124;43msplit_by_whitespace\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43mtreat_whitespace_as_suffix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43msplit_digits\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x19\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;130;43;01m\\x63\u001b[39;49;00m\u001b[38;5;124;43montrol_symbols\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43muser_defined_symbols\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1f\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mrequired_chars\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mbyte_fallback\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m# \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43mvocabulary_output_piece_score\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m  \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;124;43mhard_vocab_limit\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m! \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43muse_all_vocab\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43munk_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m( \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x62\u001b[39;49;00m\u001b[38;5;124;43mos_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mos_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m* \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mpad_id\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m-1\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43munk_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m- \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mbos_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m<s>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x17\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43meos_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m/ \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m</s>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mpad_piece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m<pad>\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;124;43munk_surface\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\xe2\u001b[39;49;00m\u001b[38;5;130;43;01m\\x81\u001b[39;49;00m\u001b[38;5;130;43;01m\\x87\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;124;43mtrain_extremely_large_corpus\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x31\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;130;43;01m\\x66\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;124;43mlse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mModelType\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNIGRAM\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;124;43mPE\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mWORD\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x43\u001b[39;49;00m\u001b[38;5;124;43mHAR\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xd1\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mNormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1c\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x14\u001b[39;49;00m\u001b[38;5;124;43mprecompiled_charsmap\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x61\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;124;43m_dummy_prefix\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m&\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;124;43mremove_extra_whitespaces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mscape_whitespaces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1e\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x16\u001b[39;49;00m\u001b[38;5;124;43mnormalization_rule_tsv\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mSelfTestData\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x33\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43msamples\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.sentencepiece.SelfTestData.Sample\u001b[39;49m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mSample\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mxpected\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\xfe\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mModelProto\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x37\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mpieces\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.sentencepiece.ModelProto.SentencePiece\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x30\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mtrainer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.TrainerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x36\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0f\u001b[39;49;00m\u001b[38;5;124;43mnormalizer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.NormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x33\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;124;43mself_test_data\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1b\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.SelfTestData\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x38\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x11\u001b[39;49;00m\u001b[38;5;130;43;01m\\x64\u001b[39;49;00m\u001b[38;5;130;43;01m\\x65\u001b[39;49;00m\u001b[38;5;124;43mnormalizer_spec\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;130;43;01m\\x1d\u001b[39;49;00m\u001b[38;5;124;43m.sentencepiece.NormalizerSpec\u001b[39;49m\u001b[38;5;130;43;01m\\x1a\u001b[39;49;00m\u001b[38;5;130;43;01m\\xd2\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mSentencePiece\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;130;43;01m\\x18\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;130;43;01m\\x0e\u001b[39;49;00m\u001b[38;5;130;43;01m\\x32\u001b[39;49;00m\u001b[38;5;124;43m,.sentencepiece.ModelProto.SentencePiece.Type:\u001b[39;49m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mNORMAL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mNORMAL\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;124;43mUNKNOWN\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0b\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x07\u001b[39;49;00m\u001b[38;5;130;43;01m\\x43\u001b[39;49;00m\u001b[38;5;124;43mONTROL\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x0c\u001b[39;49;00m\u001b[38;5;124;43mUSER_DEFINED\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x04\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;124;43mYTE\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;130;43;01m\\x12\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\x06\u001b[39;49;00m\u001b[38;5;124;43mUNUSED\u001b[39;49m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x05\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\x08\u001b[39;49;00m\u001b[38;5;130;43;01m\\xc8\u001b[39;49;00m\u001b[38;5;130;43;01m\\x01\u001b[39;49;00m\u001b[38;5;130;43;01m\\x10\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x80\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;130;43;01m\\x42\u001b[39;49;00m\u001b[38;5;130;43;01m\\x02\u001b[39;49;00m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;130;43;01m\\x03\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m _TRAINERSPEC_MODELTYPE \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[1;32m     86\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentencepiece.TrainerSpec.ModelType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1347\u001b[39m,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m _sym_db\u001b[38;5;241m.\u001b[39mRegisterEnumDescriptor(_TRAINERSPEC_MODELTYPE)\n",
      "File \u001b[0;32m/opt/conda/envs/cv/lib/python3.10/site-packages/google/protobuf/descriptor.py:1072\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool: duplicate file name sentencepiece_model.proto"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Load the pre-trained Donut model and processor\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize and convert image to RGB\n",
    "    resized_image = image.resize((1000, 1000)).convert(\"RGB\")\n",
    "    return resized_image\n",
    "\n",
    "def ocr_readability_score(image):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Prepare the image for Donut\n",
    "        pixel_values = processor(preprocessed_image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Perform OCR using Donut\n",
    "        generated_ids = model.generate(pixel_values, max_length=512)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Calculate the readability score based on the number of detected elements\n",
    "        num_chars = len(generated_text)\n",
    "        return num_chars\n",
    "    except Exception as e:\n",
    "        print(f\"Error in OCR processing: {e}\")\n",
    "        return 0\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    # Rotate the image by the specified angle\n",
    "    return image.rotate(angle, expand=True)\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    angles = list(range(0, 360, 15))  # Rotate every 15 degrees\n",
    "    transformations = {f\"rot{angle}\": rotate_image(img, angle) for angle in angles}\n",
    "    transformations[\"original\"] = img\n",
    "    transformations.update({f\"flip_horizontal_rot{angle}\": rotate_image(img.transpose(Image.FLIP_LEFT_RIGHT), angle) for angle in angles})\n",
    "    \n",
    "    best_score = 0\n",
    "    best_transformation = \"original\"\n",
    "    \n",
    "    for key, transformed_img in transformations.items():\n",
    "        score = ocr_readability_score(transformed_img)\n",
    "        print(f\"Transformation: {key}, Readability Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_transformation = key\n",
    "\n",
    "    print(f\"Best transformation: {best_transformation} with score: {best_score}\")\n",
    "    return transformations.get(best_transformation, img)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "best_img = find_best_orientation(image_path)\n",
    "\n",
    "if best_img is not None:\n",
    "    output_path = 'dj/best_oriented_image.jpg'\n",
    "    best_img.save(output_path)\n",
    "    print(f\"Best oriented image saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No image to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
