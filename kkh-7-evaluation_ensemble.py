#############################################################
## ğŸ“œ ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒ
## kimkihong / helpotcreator@gmail.com / Upstage AI Lab 3ê¸°
## 2024.07.30.í™” 10:00 ~ 2024.08.11.ì¼ 19:00
## íŒŒì¼ ì„¤ëª…:
## - ì—¬ëŸ¬ .pt íŒŒì¼ì„ ì§€ì •í•˜ë©´, ì•™ìƒë¸” í•˜ë“œ ë³´íŒ…í•˜ê³ , ê²°ê³¼ë¥¼ ë¶„ì„í•´ì¤€ë‹¤.
#############################################################

import logging
import timm
import os
import random
import torch
import pandas as pd
import numpy as np
from albumentations.pytorch import ToTensorV2
import albumentations as A
from PIL import Image
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import f1_score
import platform

os_name = platform.system()
if os_name == 'Windows':
    PRE_PATH = ''
elif os_name == 'Linux':
    PRE_PATH = '/kkh/'
elif os_name == 'Darwin': # ë§¥
    PRE_PATH = '/kkh/'
    
VALID_IMAGE_PATH = PRE_PATH + 'data/valid_sunho'
VALID_CSV_PATH = PRE_PATH + 'data/valid_sunho.csv'
TEST_IMAGE_PATH = PRE_PATH + 'data/test'
TEST_CSV_PATH = PRE_PATH + 'data/sample_submission.csv'
MODEL_SAVE_PATH = PRE_PATH + 'test/'

SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.benchmark = True
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

NUM_CLASSES = 17
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

MODEL_FILES = [
    PRE_PATH + 'data/pt/dongjae/' + 'eff-b4_0.4954_0.9248_epoch7.pt',
    PRE_PATH + 'data/pt/dongjae/' + 'eff-b4_0.5089_0.9283_epoch2.pt',
    PRE_PATH + 'data/pt/dongjae/' + 'eff-b4_0.4055_0.9239_epoch0.pt',
    PRE_PATH + 'data/pt/dongjae/' + '64-eff-b4_0.5632_0.9222_epoch0.pt',
    PRE_PATH + 'data/pt/kimkihong/' + 'efficientnet_b4_Ep2_L_0.4731_A_0.9223_F1_0.9119.pt',
]

def create_directory_with_backup(path):
    try:
        if os.path.exists(path):
            backup_path = path + '_backup'
            os.rename(path, backup_path)
            print(f"Existing folder renamed to: {backup_path}")
        os.makedirs(path)
        print(f"Folder created: {path}")
    except Exception as e:
        print(f"An error occurred: {e}")

# Dataset class ì •ì˜
class ImageDataset(Dataset):
    def __init__(self, df, image_path, transform=None):
        self.df = df
        self.image_path = image_path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df.iloc[idx]
        img = np.array(Image.open(os.path.join(self.image_path, name)).convert("RGB"))

        # ë³€í™˜ ì ìš©
        if self.transform:
            try:
                img = self.transform(image=img)['image']
            except Exception as e:
                print(f"Error in transforming image {name}: {e}")
                img = img  # ì˜ˆì™¸ê°€ ë°œìƒí•œ ê²½ìš° ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©

        return img, target

# ì´ë¯¸ì§€ ë³€í™˜ ì„¤ì •
def get_transforms():
    valid_transform = A.Compose([
        A.Resize(380, 380),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])
    return valid_transform

# ì•™ìƒë¸” voting
def majority_voting_from_preds(preds_list):
    preds_array = np.array(preds_list)
    majority_preds = []
    for i in range(len(preds_array[0])):  # preds_arrayì˜ ì—´ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡
        preds = preds_array[:, i]
        unique, counts = np.unique(preds, return_counts=True)
        chosen_pred = unique[np.argmax(counts)]
        if len(set(counts)) == 1:  # ìœ ë‹ˆí¬í•œ ê°’ì˜ ê°œìˆ˜ê°€ ëª¨ë‘ ë™ì¼í•œ ê²½ìš°
            chosen_pred = preds[0]  # ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì„ íƒí•œë‹¤.
        majority_preds.append(chosen_pred)
    return majority_preds

# í‰ê°€ ìˆ˜í–‰
def evaluate(models, loader):
    all_preds = []
    all_targets = []
    for model in models:
        model.eval()
        preds_list = []
        targets_list = []
        with torch.no_grad():
            tbar = tqdm(loader, desc="Evaluation")
            for images, targets in tbar:
                images = images.to(device)
                preds = model(images)
                preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
                targets_list.extend(targets.detach().cpu().numpy())
        all_preds.append(preds_list)
        all_targets.append(targets_list)

    ensemble_preds = majority_voting_from_preds(all_preds)
    return ensemble_preds, all_targets[0]

# ìµœì¢… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
def run_final_test(models, test_loader, test_df):
    all_preds = []
    for model in models:
        model.eval()
        preds_list = []
        with torch.no_grad():
            tbar = tqdm(test_loader, desc="Final Test")
            for images, _ in tbar:
                images = images.to(device)
                preds = model(images)
                preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        all_preds.append(preds_list)
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    ensemble_preds = majority_voting_from_preds(all_preds)
    
    # ê²°ê³¼ ì €ì¥
    test_df['target'] = ensemble_preds
    test_df.to_csv(os.path.join(MODEL_SAVE_PATH, 'ensemble_test.csv'), index=False)
    print(f"Final test predictions saved to {os.path.join(MODEL_SAVE_PATH, 'ensemble_test.csv')}")

# ë©”ì¸ í•¨ìˆ˜
def run_final_test_pipeline():
    test_df = pd.read_csv(TEST_CSV_PATH)
    valid_df = pd.read_csv(VALID_CSV_PATH)
    valid_transform = get_transforms()

    test_dataset = ImageDataset(test_df, TEST_IMAGE_PATH, transform=valid_transform)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    valid_dataset = ImageDataset(valid_df, VALID_IMAGE_PATH, transform=valid_transform)
    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    models = []
    for model_file in MODEL_FILES:
        if 'efficientnet_b4' in model_file:
            model_name = 'tf_efficientnet_b4'
        elif 'eff' in model_file:  # íŒŒì¼ëª…ì— 'efficientnet'ì´ í¬í•¨ëœ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ b4ë¡œ ì²˜ë¦¬
            model_name = 'tf_efficientnet_b4'
        elif 'efficientnet_b0' in model_file:
            model_name = 'efficientnet_b0'
        elif 'resnet50' in model_file:
            model_name = 'resnet50'
        else:
            raise ValueError(f"Unknown model file: {model_file}")
        
        model = timm.create_model(model_name, pretrained=False, num_classes=NUM_CLASSES, in_chans=3)

        # map_location ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ CPUì—ì„œ ë¡œë“œ
        # model.load_state_dict(torch.load(model_file, map_location=device))
        # model = model.to(device)
        # models.append(model)

        state_dict = torch.load(model_file, map_location=device)
        model_state_dict = model.state_dict()
        model_state_dict.update(state_dict)
        model.load_state_dict(model_state_dict)
        model = model.to(device)
        models.append(model)

    # Validation í‰ê°€ ìˆ˜í–‰
    val_preds, val_targets = evaluate(models, valid_loader)
    valid_df['predictions'] = val_preds
    valid_df.to_csv(os.path.join(MODEL_SAVE_PATH, 'ensemble_valid.csv'), index=False)
    print(f"Validation predictions saved to {os.path.join(MODEL_SAVE_PATH, 'ensemble_valid.csv')}")

    # F1 ì ìˆ˜ ê³„ì‚° ë° ì €ì¥
    f1 = f1_score(val_targets, val_preds, average='macro')
    f1_score_path = os.path.join(MODEL_SAVE_PATH, f'ensemble_valid_f1_{f1:.4f}.txt')
    with open(f1_score_path, 'w') as f:
        f.write(f'Validation F1 Score: {f1:.4f}\n')
    print(f"Validation F1 score saved to {f1_score_path}")

    # ìµœì¢… í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    run_final_test(models, test_loader, test_df)

if __name__ == "__main__":
    create_directory_with_backup(MODEL_SAVE_PATH)
    run_final_test_pipeline()
