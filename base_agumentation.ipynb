{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from glob import glob \n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations import ImageOnlyTransform\n",
    "from augraphy import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data 증강 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = '/upstage-cv-classification-cv2/'\n",
    "TRAIN_IMAGE_PATH = PRE_PATH + 'data/train'\n",
    "TRAIN_AUG_IMAGE_PATH = PRE_PATH + 'data/train_base_aug' # 증강한 이미지들을 담을 폴더명 미리 지정\n",
    "\n",
    "META_CSV_PATH = PRE_PATH + 'data/meta.csv'\n",
    "META_DF = pd.read_csv(META_CSV_PATH)\n",
    "\n",
    "TRAIN_CSV_PATH = PRE_PATH + 'data/train.csv'\n",
    "TRAIN_DF = pd.read_csv(TRAIN_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아무런 변환 없음\n",
    "original = A.Compose([])\n",
    "\n",
    "# 회전 변환 + 수평 뒤집기\n",
    "hf_rotate_000 = A.Compose([A.HorizontalFlip(p=1)])\n",
    "hf_rotate_045 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(45, 45), p=1)])\n",
    "hf_rotate_090 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(90, 90), p=1)])\n",
    "hf_rotate_135 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(135, 135), p=1)])\n",
    "hf_rotate_180 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(180, 180), p=1)])\n",
    "hf_rotate_225 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(225, 225), p=1)])\n",
    "hf_rotate_270 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(270, 270), p=1)])\n",
    "hf_rotate_315 = A.Compose([A.HorizontalFlip(p=1), A.Rotate(limit=(315, 315), p=1)])\n",
    "\n",
    "# 회전 변환\n",
    "rotate_045 = A.Compose([A.Rotate(limit=(45, 45), p=1)])\n",
    "rotate_090 = A.Compose([A.Rotate(limit=(90, 90), p=1)])\n",
    "rotate_135 = A.Compose([A.Rotate(limit=(135, 135), p=1)])\n",
    "rotate_180 = A.Compose([A.Rotate(limit=(180, 180), p=1)])\n",
    "rotate_225 = A.Compose([A.Rotate(limit=(225, 225), p=1)])\n",
    "rotate_270 = A.Compose([A.Rotate(limit=(270, 270), p=1)])\n",
    "rotate_315 = A.Compose([A.Rotate(limit=(315, 315), p=1)])\n",
    "\n",
    "# 여러 이미지 변환을 정의한 리스트입니다. 각 변환은 튜플로 되어 있으며, 튜플의 첫 번째 요소는 변환의 접두사(prefix)이고, 두 번째 요소는 변환 객체입니다.\n",
    "base_aug_types = [\n",
    "    (f\"original_\", original),\n",
    "    (f\"hf_r000_\", hf_rotate_000),\n",
    "    (f\"hf_r045_\", hf_rotate_045),\n",
    "    (f\"hf_r090_\", hf_rotate_090),\n",
    "    (f\"hf_r135_\", hf_rotate_135),\n",
    "    (f\"hf_r180_\", hf_rotate_180),\n",
    "    (f\"hf_r225_\", hf_rotate_225),\n",
    "    (f\"hf_r270_\", hf_rotate_270),\n",
    "    (f\"hf_r315_\", hf_rotate_315),\n",
    "    (f\"r045_\", rotate_045),\n",
    "    (f\"r090_\", rotate_090),\n",
    "    (f\"r135_\", rotate_135),\n",
    "    (f\"r180_\", rotate_180),\n",
    "    (f\"r225_\", rotate_225),\n",
    "    (f\"r270_\", rotate_270),\n",
    "    (f\"r315_\", rotate_315) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image augmentation: 100%|██████████| 1570/1570 [00:51<00:00, 30.31it/s]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "targets = []\n",
    "\n",
    "for index, ID, target in tqdm(TRAIN_DF.itertuples(), total=TRAIN_DF.shape[0], desc='Image augmentation'):\n",
    "    image_path = os.path.join(TRAIN_IMAGE_PATH, ID)\n",
    "    image = np.array(Image.open(image_path))\n",
    "    \n",
    "    # `base_aug_types`에 정의된 각 변환에 대해 반복합니다.\n",
    "    for prefix, aug_function in base_aug_types:\n",
    "        # 변환 함수를 사용하여 이미지를 변환합니다.\n",
    "        transformed_image = aug_function(image=image)['image']\n",
    "        new_ID = prefix + ID\n",
    "        \n",
    "        ids.append(new_ID)\n",
    "        targets.append(target)\n",
    "        Image.fromarray(transformed_image).save(os.path.join(TRAIN_AUG_IMAGE_PATH, new_ID))\n",
    "\n",
    "aug_data = {\n",
    "    'ID': ids,\n",
    "    'target': targets\n",
    "}\n",
    "aug_data = pd.DataFrame(aug_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 원본 데이터 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_files(source_dir, dest_dir):\n",
    "    # 소스 폴더가 존재하는지 확인합니다.\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Error: Source directory '{source_dir}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 소스 디렉토리의 모든 파일을 반복합니다.\n",
    "        for filename in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            dest_file = os.path.join(dest_dir, filename)\n",
    "            \n",
    "            # 파일을 목적지 폴더로 복사합니다.\n",
    "            shutil.copy2(source_file, dest_file)\n",
    "        print(\"All files copied successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "copy_files(TRAIN_IMAGE_PATH, TRAIN_AUG_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 train_agu.csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 DataFrame `TRAIN_KR_DF`와 증강된 데이터 `aug_data`를 결합하여 새로운 DataFrame `df`를 만듭니다.\n",
    "df = pd.concat([TRAIN_DF, aug_data])\n",
    "\n",
    "# 저장할 파일 경로 정의\n",
    "TRAIN_AUG_CSV_PATH = PRE_PATH + 'data/train_base_aug.csv'\n",
    "df.to_csv(TRAIN_AUG_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 라벨링 잘 못된 데이터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_AUG_CSV_PATH)\n",
    "\n",
    "# 조건에 따라 타겟 값을 변경하는 함수입니다.\n",
    "def update_target(row):\n",
    "    if \"45f0d2dfc7e47c03\" in row['ID']: return 7\n",
    "    elif \"aec62dced7af97cd\" in row['ID']: return 14\n",
    "    elif \"8646f2c3280a4f49\" in row['ID']: return 3\n",
    "    elif \"1ec14a14bbe633db\" in row['ID']: return 7\n",
    "    elif \"7100c5c67aecadc5\" in row['ID']: return 7\n",
    "    elif \"c5182ab809478f12\" in row['ID']: return 14\n",
    "    elif \"38d1796b6ad99ddd\" in row['ID']: return 10\n",
    "    elif \"0583254a73b48ece\" in row['ID']: return 10\n",
    "    else: return row['target']\n",
    "\n",
    "df['target'] = df.apply(update_target, axis=1)\n",
    "df.to_csv(TRAIN_AUG_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
