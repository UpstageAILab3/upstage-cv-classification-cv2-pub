{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as ptim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch import optim\n",
    "from torch.optim import optimizer\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    # Python의 기본 랜덤 시드 고정\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy의 랜덤 시드 고정\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch의 랜덤 시드 고정\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # GPU 사용 시, CuDNN의 비결정적 동작 방지\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 모든 GPU에 대해 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 시드 설정\n",
    "set_random_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATH 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = '/upstage-cv-classification-cv2/data/'\n",
    "\n",
    "TRAIN_CSV_PATH = PRE_PATH + 'contra_train.csv'\n",
    "TRAIN_IMAGE_PATH = PRE_PATH + 'train_aug'\n",
    "BASE_TRAIN_CSV_PATH = PRE_PATH + 'train.csv'\n",
    "\n",
    "VALID_CSV_PATH = PRE_PATH + 'valid37.csv'\n",
    "VALID_IMAGE_PATH = PRE_PATH + 'valid'\n",
    "\n",
    "WANDB_PROJECT_NAME = 'contra_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "MODEL_NAME = 'efficientnet_b4'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = A.Compose([\n",
    "    A.Resize(height = IMG_SIZE, width = IMG_SIZE),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform = None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img1_id, img2_id, target = self.df[idx]\n",
    "        img1 = np.array(Image.open(os.path.join(self.path, img1_id)))\n",
    "        img2 = np.array(Image.open(os.path.join(self.path, img2_id)))\n",
    "        if self.transform:\n",
    "            img1 = self.transform(image = img1)['image']\n",
    "            img2 = self.transform(image = img2)['image']\n",
    "\n",
    "        return img1, img2, target\n",
    "    \n",
    "class ValidImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform = None):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        row = self.df.iloc[idx]\n",
    "        id, target = row['ID'], row['target']\n",
    "        img = np.array(Image.open(os.path.join(self.path, id)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image = img)['image']\n",
    "    \n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\n",
    "    TRAIN_CSV_PATH,\n",
    "    TRAIN_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "valid_dataset = ValidImageDataset(\n",
    "    VALID_CSV_PATH,\n",
    "    VALID_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    pin_memory= True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_df = pd.read_csv(BASE_TRAIN_CSV_PATH)\n",
    "\n",
    "class_representatives = {3 : [], 7 : []}\n",
    "\n",
    "rep_class_3_ids = base_train_df[base_train_df['target'] == 3].sample(n=30, random_state=42)['ID']\n",
    "rep_class_7_ids = base_train_df[base_train_df['target'] == 7].sample(n=30, random_state=42)['ID']\n",
    "\n",
    "for rep_class_3_id, rep_class_7_id in zip(rep_class_3_ids, rep_class_7_ids):\n",
    "    rep_class_3_image = data_transform(image = np.array(Image.open(os.path.join(PRE_PATH, 'train', rep_class_3_id))))['image']\n",
    "    rep_class_7_image = data_transform(image = np.array(Image.open(os.path.join(PRE_PATH, 'train', rep_class_7_id))))['image']\n",
    "\n",
    "    class_representatives[3].append(rep_class_3_image)\n",
    "    class_representatives[7].append(rep_class_7_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetEmbedding(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.classifier = nn.Linear(in_features, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin = 1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min = 0.0), 2))\n",
    "        return loss_contrastive\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b4.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b4.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = timm.create_model(model_name = MODEL_NAME, pretrained=True)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 초기화\n",
    "model = EfficientNetEmbedding(base_model).to(device)\n",
    "criterion = ContrastiveLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjsgh2770\u001b[0m (\u001b[33mprefer_leee\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240812_112525-5t0lifr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prefer_leee/contra_train/runs/5t0lifr5' target=\"_blank\">lively-lion-18</a></strong> to <a href='https://wandb.ai/prefer_leee/contra_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prefer_leee/contra_train' target=\"_blank\">https://wandb.ai/prefer_leee/contra_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prefer_leee/contra_train/runs/5t0lifr5' target=\"_blank\">https://wandb.ai/prefer_leee/contra_train/runs/5t0lifr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.2316: 100%|██████████| 250/250 [00:43<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.3078: 100%|██████████| 250/250 [00:42<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Loss: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.3530: 100%|██████████| 250/250 [00:42<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Loss: 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.2485: 100%|██████████| 250/250 [00:42<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Loss: 0.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.2643: 100%|██████████| 250/250 [00:42<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Loss: 0.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 루프\n",
    "\n",
    "wandb.init(project = WANDB_PROJECT_NAME)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader)\n",
    "    for img1, img2, label in pbar:\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output1 = model(img1)\n",
    "        output2 = model(img2)\n",
    "        \n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_description(f\"Loss : {loss.item():.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            'train_loss_step' : loss.item() \n",
    "        })\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, image, class_representatives, device):\n",
    "    model.eval()\n",
    "    image = image.to(device)\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    predicted_class = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_embedding = model(image)\n",
    "\n",
    "    for class_label, rep_images in class_representatives.items():\n",
    "        total_dist = 0\n",
    "        for rep_image in rep_images:\n",
    "            rep_image = rep_image.to(device)\n",
    "            with torch.no_grad():\n",
    "                rep_embedding = model(rep_image.unsqueeze(0))\n",
    "\n",
    "            distance = torch.norm(image_embedding - rep_embedding).item()\n",
    "            total_dist += distance\n",
    "\n",
    "        mean_dist = total_dist / len(rep_images)\n",
    "\n",
    "        if mean_dist < min_distance:\n",
    "            min_distance = mean_dist\n",
    "            predicted_class = class_label\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "valid_pbar = tqdm(valid_loader)\n",
    "for img, target in valid_pbar:\n",
    "    pred = predict_class(model, img, class_representatives, device)\n",
    "\n",
    "    result_list.append({\"pred\" : pred, \"target\" : target.item()})\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.631578947368421\n",
      "Acc : 0.5625\n"
     ]
    }
   ],
   "source": [
    "pred_list = result_df['pred'].to_list()\n",
    "target_list = result_df['target'].to_list()\n",
    "\n",
    "\n",
    "print(f\"f1 score : {f1_score(target_list, pred_list, pos_label=3)}\")\n",
    "print(f\"Acc : {accuracy_score(target_list, pred_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
