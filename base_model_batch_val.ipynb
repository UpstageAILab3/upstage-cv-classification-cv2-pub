{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PATH\n",
    "TRAIN_AUG_CSV_PATH = '/upstage-cv-classification-cv2/data/train_aug_gaussian.csv'\n",
    "TRAIN_AUG_IMAGE_PATH = '/upstage-cv-classification-cv2/data/train_aug_gaussian'\n",
    "\n",
    "VALID_CSV_PATH = '/upstage-cv-classification-cv2/data/valid.csv'\n",
    "VALID_IMAGE_PATH = '/upstage-cv-classification-cv2/data/valid'\n",
    "\n",
    "TEST_CSV_PATH = '/upstage-cv-classification-cv2/data/sample_submission.csv'\n",
    "TEST_IMAGE_PATH = '/upstage-cv-classification-cv2/data/test'\n",
    "\n",
    "RESULT_CSV_PATH = '/upstage-cv-classification-cv2'\n",
    "\n",
    "WANDB_PROJECT_NAME = 'cv_competition_batchval'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "img_size = 380\n",
    "LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "\n",
    "patience = 5\n",
    "min_delta = 0.001 # 성능 개선의 최소 변화량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37680 3140\n"
     ]
    }
   ],
   "source": [
    "# test image 변환\n",
    "data_transform = A.Compose([\n",
    "    A.Resize(height = img_size, width = img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image = img)['image']\n",
    "    \n",
    "        return img, target\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.df[:, 1] \n",
    "\n",
    "trn_dataset = ImageDataset(\n",
    "    TRAIN_AUG_CSV_PATH,\n",
    "    TRAIN_AUG_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "val_dataset = ImageDataset(\n",
    "    VALID_CSV_PATH,\n",
    "    VALID_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    TEST_CSV_PATH,\n",
    "    TEST_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "labels = trn_dataset.get_labels()\n",
    "labels = labels.astype(int)\n",
    "\n",
    "# DataLoader\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory = True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b4.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b4.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (classifier.weight, classifier.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = timm.create_model('efficientnet_b4',\n",
    "                        pretrained=True,\n",
    "                        num_classes = 17).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(loader, model, loss_fn, device, epoch):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "\n",
    "    preds_list =[]\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader)\n",
    "        for step, (image, targets) in enumerate(pbar):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "       \n",
    "            valid_loss += loss.item()\n",
    "        \n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"valid_step\" : epoch * len(loader) + step,\n",
    "                \"valid_loss_step\" : loss.item()\n",
    "            })\n",
    "\n",
    "    valid_loss /= len(loader)\n",
    "    valid_acc = accuracy_score(targets_list, preds_list)\n",
    "    valid_f1 = f1_score(targets_list, preds_list, average = 'macro')\n",
    "\n",
    "    ret = {\n",
    "        \"epoch\" : epoch,\n",
    "        \"valid_loss\" : valid_loss,\n",
    "        \"valid_acc\" : valid_acc,\n",
    "        \"valid_f1\" : valid_f1\n",
    "    }\n",
    "\n",
    "    wandb.log({\n",
    "        \"valid_epoch\" : epoch,\n",
    "        \"val_loss_epoch\" : valid_loss,\n",
    "        \"val_acc\" : valid_acc,\n",
    "        \"val_f1\" : valid_f1\n",
    "    })\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습\n",
    "def train_one_epoch(train_loader, valid_loader, model, optimizer, loss_fn, device, epoch):\n",
    "    global patience_counter, best_valid_loss, f1_scores, valid_losses, trained_models\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    preds_list =[]\n",
    "    targets_list = []\n",
    "\n",
    "    is_earlystop = False\n",
    "\n",
    "    pbar = tqdm(train_loader)\n",
    "    for step, (image, targets) in enumerate(pbar):\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none = True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"train_step\" : epoch * len(train_loader) + step,\n",
    "            \"train_loss_step\" : loss.item()\n",
    "        })\n",
    "\n",
    "        # 100 step 마다 validation 하기\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"-------------- step : { epoch * len(train_loader) + step} --------------\")\n",
    "            val_ret =  valid_one_epoch(val_loader, model, loss_fn, device, epoch)\n",
    "\n",
    "            f1_scores.append(val_ret['valid_f1'])\n",
    "            valid_losses.append(val_ret['valid_loss'])\n",
    "            trained_models.append(model)\n",
    "\n",
    "            print(f\"valid loss : {val_ret['valid_loss']}\")\n",
    "            print(f\"valid f1 : {val_ret['valid_f1']}\")\n",
    "\n",
    "            # 성능 개선 됨\n",
    "            if val_ret['valid_loss'] < best_valid_loss - min_delta:\n",
    "                best_valid_loss = val_ret['valid_loss']\n",
    "                patience_counter = 0  \n",
    "                \n",
    "            # 성능 개선 되지 않음\n",
    "            else:\n",
    "                patience_counter += 1  \n",
    "\n",
    "            # 성능 개선이 patience 만큼 안되면 학습 중단\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                is_earlystop = True\n",
    "                break\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average = 'macro')\n",
    "\n",
    "    ret = {\n",
    "        \"isEarlyStop\" : is_earlystop,\n",
    "        \"model\" : model,\n",
    "        \"train_epoch\" : epoch,\n",
    "        \"train_loss\" : train_loss,\n",
    "        \"tarin_acc\" : train_acc,\n",
    "        \"train_f1\" : train_f1\n",
    "    }\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_epoch\" : epoch,\n",
    "        \"train_loss_epoch\" : train_loss,\n",
    "        \"train_acc\" : train_acc,\n",
    "        \"train_f1\" : train_f1\n",
    "    })\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a213a1d9fc430f94d7a661123887a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112243102656471, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2951:   8%|▊         | 99/1178 [00:39<07:01,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 99 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5840: 100%|██████████| 10/10 [00:01<00:00,  6.44it/s]\n",
      "Loss: 0.2951:   8%|▊         | 100/1178 [00:40<15:24,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.5221376433968544\n",
      "valid f1 : 0.8052011986217086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3149:  17%|█▋        | 199/1178 [01:18<06:11,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 199 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3598: 100%|██████████| 10/10 [00:01<00:00,  6.50it/s]\n",
      "Loss: 0.3149:  17%|█▋        | 200/1178 [01:20<13:43,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.5180131688714027\n",
      "valid f1 : 0.8282333615209465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2019:  25%|██▌       | 299/1178 [01:57<05:30,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 299 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2534: 100%|██████████| 10/10 [00:01<00:00,  6.33it/s]\n",
      "Loss: 0.2019:  25%|██▌       | 300/1178 [01:59<12:30,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.6410200595855713\n",
      "valid f1 : 0.8227452789452518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3793:  34%|███▍      | 399/1178 [02:37<04:53,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 399 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4563: 100%|██████████| 10/10 [00:01<00:00,  6.53it/s]\n",
      "Loss: 0.3793:  34%|███▍      | 400/1178 [02:38<10:52,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.518449530005455\n",
      "valid f1 : 0.8292597277506627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0342:  42%|████▏     | 499/1178 [03:16<04:17,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 499 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9336: 100%|██████████| 10/10 [00:01<00:00,  6.44it/s]\n",
      "Loss: 0.0342:  42%|████▏     | 500/1178 [03:17<09:33,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.47978816032409666\n",
      "valid f1 : 0.8478118753098304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0205:  51%|█████     | 599/1178 [03:55<03:38,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 599 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3530: 100%|██████████| 10/10 [00:01<00:00,  6.60it/s]\n",
      "Loss: 0.0205:  51%|█████     | 600/1178 [03:57<08:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.5024144098162651\n",
      "valid f1 : 0.8823394159177549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3234:  59%|█████▉    | 699/1178 [04:34<03:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 699 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4726: 100%|██████████| 10/10 [00:01<00:00,  6.62it/s]\n",
      "Loss: 0.3234:  59%|█████▉    | 700/1178 [04:36<06:39,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.5111183792352676\n",
      "valid f1 : 0.8612082297865067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2608:  68%|██████▊   | 799/1178 [05:14<02:22,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 799 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0783: 100%|██████████| 10/10 [00:01<00:00,  6.43it/s]\n",
      "Loss: 0.2608:  68%|██████▊   | 800/1178 [05:15<05:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.37972619459033014\n",
      "valid f1 : 0.8776853531244752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0605:  76%|███████▋  | 899/1178 [05:53<01:46,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 899 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3123: 100%|██████████| 10/10 [00:01<00:00,  6.25it/s]\n",
      "Loss: 0.0605:  76%|███████▋  | 900/1178 [05:55<03:59,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.6480358809232711\n",
      "valid f1 : 0.821977716659528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1843:  85%|████████▍ | 999/1178 [06:32<01:07,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 999 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0286: 100%|██████████| 10/10 [00:01<00:00,  6.22it/s]\n",
      "Loss: 0.1843:  85%|████████▍ | 1000/1178 [06:34<02:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.48168935514986516\n",
      "valid f1 : 0.8179085487027761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0677:  93%|█████████▎| 1099/1178 [07:12<00:29,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 1099 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1016: 100%|██████████| 10/10 [00:01<00:00,  6.35it/s]\n",
      "Loss: 0.0677:  93%|█████████▎| 1100/1178 [07:13<01:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.6673544995486737\n",
      "valid f1 : 0.8331898957873983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2374: 100%|██████████| 1178/1178 [07:43<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1732:   8%|▊         | 99/1178 [00:39<07:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 1277 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4323: 100%|██████████| 10/10 [00:01<00:00,  6.57it/s]\n",
      "Loss: 0.1732:   8%|▊         | 100/1178 [00:40<15:16,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.4134209968149662\n",
      "valid f1 : 0.9063142432019478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0894:  17%|█▋        | 199/1178 [01:18<06:07,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- step : 1377 --------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0446: 100%|██████████| 10/10 [00:01<00:00,  6.60it/s]\n",
      "Loss: 0.0894:  17%|█▋        | 199/1178 [01:19<06:32,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.38251737877726555\n",
      "valid f1 : 0.9025657436670329\n",
      "Early stopping at epoch 1\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "\n",
    "f1_scores = []\n",
    "valid_losses = []\n",
    "trained_models = []\n",
    "\n",
    "patient_counter = 0\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT_NAME, name=\"gaussian\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"{epoch} epoch\")\n",
    "\n",
    "    trn_ret = train_one_epoch(trn_loader, val_loader, model, optimizer, loss_fn, device, epoch)\n",
    "    is_earlystop = trn_ret['isEarlyStop']\n",
    "\n",
    "    if is_earlystop:\n",
    "        break\n",
    "    \n",
    "\n",
    "best_model_idx = np.argmin(np.array(valid_losses))\n",
    "best_model = trained_models[best_model_idx]\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:15<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = best_model(image)\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(f\"{RESULT_CSV_PATH}/base_batch_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
