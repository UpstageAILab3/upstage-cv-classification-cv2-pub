{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed image saved to '/dj/enhanced_image_4.png'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(resized_image, (3, 3), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "    \n",
    "    # Sharpen the image\n",
    "    sharpen_kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(enhanced_image, -1, sharpen_kernel)\n",
    "    \n",
    "    # Edge detection to enhance lines\n",
    "    edges = cv2.Canny(sharpened, 50, 150, apertureSize=3)\n",
    "    \n",
    "    # Ensure edges and sharpened image have the same shape\n",
    "    if len(edges.shape) == 2:\n",
    "        edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        edges_colored = edges\n",
    "\n",
    "    # Ensure both images are the same size\n",
    "    sharpened_colored = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Combine the edges with the sharpened image\n",
    "    combined = cv2.addWeighted(sharpened_colored, 0.8, edges_colored, 0.2, 0)\n",
    "\n",
    "    return combined\n",
    "\n",
    "def save_preprocessed_image(input_path, output_path):\n",
    "    try:\n",
    "        processed_image = preprocess_image(input_path)\n",
    "        cv2.imwrite(output_path, processed_image)\n",
    "        print(f\"Preprocessed image saved to '{output_path}'\")\n",
    "    except Exception as e:\n",
    "        print(\"Error during preprocessing:\", e)\n",
    "\n",
    "# Example usage\n",
    "image_path = '/dj/data/test/4a8b25f0c83e9553.jpg'\n",
    "output_path = '/dj/enhanced_image_4.png'\n",
    "save_preprocessed_image(image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Additional noise removal using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    denoised = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Apply CLAHE to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(denoised)\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    text = pytesseract.image_to_string(processed_image, lang='kor')\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "image_path = '/dj/data/test/4a8b25f0c83e9553.jpg'\n",
    "extracted_text = ocr_image(image_path)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (591, 443, 3)\n",
      "Resized image shape: (1182, 886, 3)\n",
      "Grayscale image shape: (1182, 886)\n",
      "Edges image shape: (1182, 886)\n",
      "Dilated edges image shape: (1182, 886)\n",
      "Edges colored image shape: (1182, 886, 3)\n",
      "Sharpened image shape: (1182, 886, 3)\n",
      "Combined image shape: (1182, 886, 3)\n",
      "Preprocessed image saved to '/dj/enhanced_image_5.png'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, output_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    print(f\"Original image shape: {image.shape}\")\n",
    "\n",
    "    # Resize image to improve processing\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    print(f\"Resized image shape: {resized_image.shape}\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    print(f\"Grayscale image shape: {gray.shape}\")\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Edge enhancement using Canny Edge Detection\n",
    "    edges = cv2.Canny(blurred, 100, 200)\n",
    "    print(f\"Edges image shape: {edges.shape}\")\n",
    "\n",
    "    # Dilate edges to make them more prominent\n",
    "    dilated_edges = cv2.dilate(edges, np.ones((1, 1), np.uint8), iterations=1)\n",
    "    print(f\"Dilated edges image shape: {dilated_edges.shape}\")\n",
    "\n",
    "    # Convert edges back to BGR\n",
    "    edges_colored = cv2.cvtColor(dilated_edges, cv2.COLOR_GRAY2BGR)\n",
    "    print(f\"Edges colored image shape: {edges_colored.shape}\")\n",
    "\n",
    "    # Sharpen the image\n",
    "    kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                                  [-1, 9,-1],\n",
    "                                  [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(resized_image, -1, kernel_sharpening)\n",
    "    print(f\"Sharpened image shape: {sharpened.shape}\")\n",
    "\n",
    "    # Combine the edges with the sharpened image\n",
    "    combined = cv2.addWeighted(sharpened, 0.8, edges_colored, 0.2, 0)\n",
    "    print(f\"Combined image shape: {combined.shape}\")\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(output_path, combined)\n",
    "    print(f\"Preprocessed image saved to '{output_path}'\")\n",
    "    \n",
    "    \n",
    "image_path = '/dj/data/test/0a95b7e3f2bdc376.jpg'\n",
    "output_path = '/dj/enhanced_image_5.png'\n",
    "preprocess_image(image_path, output_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_image() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dj/data/test/4a8b25f0c83e9553.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dj/enhanced_image_5.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_image() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import restoration, exposure\n",
    "\n",
    "def enhance_document_image(image_path, output_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    print(f\"Original image shape: {image.shape}\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    print(f\"Grayscale image shape: {gray.shape}\")\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive histogram equalization to enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_contrast = clahe.apply(blurred)\n",
    "\n",
    "    # Edge enhancement using Canny edge detection\n",
    "    edges = cv2.Canny(enhanced_contrast, 50, 150)\n",
    "    print(f\"Edges image shape: {edges.shape}\")\n",
    "\n",
    "    # Denoise the image using Non-Local Means Denoising\n",
    "    denoised = restoration.denoise_nl_means(enhanced_contrast, h=1.15)\n",
    "    denoised = (denoised * 255).astype(np.uint8)\n",
    "\n",
    "    # Sharpen the image\n",
    "    kernel_sharpening = np.array([[-1, -1, -1],\n",
    "                                  [-1, 9, -1],\n",
    "                                  [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel_sharpening)\n",
    "    print(f\"Sharpened image shape: {sharpened.shape}\")\n",
    "\n",
    "    # Combine the edges with the sharpened image\n",
    "    combined = cv2.addWeighted(sharpened, 0.8, edges, 0.2, 0)\n",
    "    print(f\"Combined image shape: {combined.shape}\")\n",
    "\n",
    "    # Save the enhanced image\n",
    "    cv2.imwrite(output_path, combined)\n",
    "    print(f\"Enhanced image saved to '{output_path}'\")\n",
    "    \n",
    "    \n",
    "image_path = '/dj/data/test/4a8b25f0c83e9553.jpg'\n",
    "output_path = '/dj/enhanced_image_5.png'\n",
    "preprocess_image(image_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (2364, 1772, 3)\n",
      "Angle: 0, Readability Score: 1077\n",
      "Flipped Angle: 0, Readability Score: 1440\n",
      "Angle: 15, Readability Score: 3\n",
      "Flipped Angle: 15, Readability Score: 3\n",
      "Angle: 30, Readability Score: 3\n",
      "Flipped Angle: 30, Readability Score: 3\n",
      "Angle: 45, Readability Score: 3\n",
      "Flipped Angle: 45, Readability Score: 3\n",
      "Angle: 60, Readability Score: 3\n",
      "Flipped Angle: 60, Readability Score: 3\n",
      "Angle: 75, Readability Score: 40\n",
      "Flipped Angle: 75, Readability Score: 17\n",
      "Angle: 90, Readability Score: 110\n",
      "Flipped Angle: 90, Readability Score: 133\n",
      "Angle: 105, Readability Score: 3\n",
      "Flipped Angle: 105, Readability Score: 3\n",
      "Angle: 120, Readability Score: 3\n",
      "Flipped Angle: 120, Readability Score: 3\n",
      "Angle: 135, Readability Score: 3\n",
      "Flipped Angle: 135, Readability Score: 3\n",
      "Angle: 150, Readability Score: 3\n",
      "Flipped Angle: 150, Readability Score: 3\n",
      "Angle: 165, Readability Score: 69\n",
      "Flipped Angle: 165, Readability Score: 13\n",
      "Angle: 180, Readability Score: 1085\n",
      "Flipped Angle: 180, Readability Score: 1416\n",
      "Angle: 195, Readability Score: 3\n",
      "Flipped Angle: 195, Readability Score: 3\n",
      "Angle: 210, Readability Score: 3\n",
      "Flipped Angle: 210, Readability Score: 3\n",
      "Angle: 225, Readability Score: 3\n",
      "Flipped Angle: 225, Readability Score: 3\n",
      "Angle: 240, Readability Score: 3\n",
      "Flipped Angle: 240, Readability Score: 3\n",
      "Angle: 255, Readability Score: 3\n",
      "Flipped Angle: 255, Readability Score: 3\n",
      "Angle: 270, Readability Score: 40\n",
      "Flipped Angle: 270, Readability Score: 97\n",
      "Angle: 285, Readability Score: 3\n",
      "Flipped Angle: 285, Readability Score: 3\n",
      "Angle: 300, Readability Score: 3\n",
      "Flipped Angle: 300, Readability Score: 3\n",
      "Angle: 315, Readability Score: 3\n",
      "Flipped Angle: 315, Readability Score: 3\n",
      "Angle: 330, Readability Score: 3\n",
      "Flipped Angle: 330, Readability Score: 3\n",
      "Angle: 345, Readability Score: 3\n",
      "Flipped Angle: 345, Readability Score: 59\n",
      "Best oriented image saved to 'dj/best_oriented_image.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def rotate_and_flip_image(image, angle):\n",
    "    # Rotate image\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def calculate_readability_score(image):\n",
    "    # Convert the image to PIL format\n",
    "    pil_image = Image.fromarray(image)\n",
    "    # Use pytesseract to do OCR on the image\n",
    "    text = pytesseract.image_to_string(pil_image, lang='kor')\n",
    "    # Readability score based on the length of extracted text\n",
    "    readability_score = len(text)\n",
    "    return readability_score, text\n",
    "\n",
    "def find_best_orientation(image_path):\n",
    "    # Load the preprocessed image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    print(f\"Original image shape: {image.shape}\")\n",
    "\n",
    "    best_score = 0\n",
    "    best_image = None\n",
    "    best_text = \"\"\n",
    "    angles = [0,15, 30,45, 60,75, 90,105, 120,135, 150,165, 180,195, 210,225, 240,255, 270,285, 300,315, 330, 345]\n",
    "\n",
    "    for angle in angles:\n",
    "        # Rotate the image\n",
    "        rotated_image = rotate_and_flip_image(image, angle)\n",
    "        # Calculate readability score for the rotated image\n",
    "        score, text = calculate_readability_score(rotated_image)\n",
    "        print(f\"Angle: {angle}, Readability Score: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_image = rotated_image\n",
    "            best_text = text\n",
    "\n",
    "        # Flip the image and calculate the readability score for the flipped image\n",
    "        flipped_image = cv2.flip(rotated_image, 1)\n",
    "        score, text = calculate_readability_score(flipped_image)\n",
    "        print(f\"Flipped Angle: {angle}, Readability Score: {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_image = flipped_image\n",
    "            best_text = text\n",
    "\n",
    "    return best_image, best_text\n",
    "\n",
    "# Example usage\n",
    "image_path = '/dj/enhanced_image.png/1acbab3967fe133b_out.jpg'\n",
    "best_image, best_text = find_best_orientation(image_path)\n",
    "\n",
    "if best_image is not None:\n",
    "    cv2.imwrite('dj/best_oriented_image_4.jpg', best_image)\n",
    "    print(\"Best oriented image saved to 'dj/best_oriented_image.jpg'\")\n",
    "else:\n",
    "    print(\"No suitable transformation found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (591, 443, 3)\n",
      "Resized image shape: (1182, 886, 3)\n",
      "Gray image shape: (1182, 886)\n",
      "Blurred image shape: (1182, 886)\n",
      "Edges image shape: (1182, 886)\n",
      "Preprocessed image saved to 'dj/preprocessed_image_3.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image_with_canny(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    print(f\"Original image shape: {image.shape}\")\n",
    "\n",
    "    # Resize image to improve OCR accuracy\n",
    "    resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    print(f\"Resized image shape: {resized_image.shape}\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    print(f\"Gray image shape: {gray.shape}\")\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    print(f\"Blurred image shape: {blurred.shape}\")\n",
    "\n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    print(f\"Edges image shape: {edges.shape}\")\n",
    "\n",
    "    return edges\n",
    "\n",
    "def save_preprocessed_image(input_path, output_path):\n",
    "    processed_image = preprocess_image_with_canny(input_path)\n",
    "    cv2.imwrite(output_path, processed_image)\n",
    "    print(f\"Preprocessed image saved to '{output_path}'\")\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dj/data/test/0a4f2decf34d3bff.jpg'\n",
    "output_path = 'dj/preprocessed_image_3.jpg'\n",
    "save_preprocessed_image(image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
