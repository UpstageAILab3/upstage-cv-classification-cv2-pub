{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PATH\n",
    "TRAIN_AUG_CSV_PATH = '/upstage-cv-classification-cv2/data/train_semi.csv'\n",
    "TRAIN_AUG_IMAGE_PATH = '/upstage-cv-classification-cv2/data/train_semi'\n",
    "\n",
    "VALID_CSV_PATH = '/upstage-cv-classification-cv2/data/valid.csv'\n",
    "VALID_IMAGE_PATH = '/upstage-cv-classification-cv2/data/valid'\n",
    "\n",
    "TEST_CSV_PATH = '/upstage-cv-classification-cv2/data/sample_submission.csv'\n",
    "TEST_IMAGE_PATH = '/upstage-cv-classification-cv2/data/test'\n",
    "\n",
    "RESULT_CSV_PATH = '/upstage-cv-classification-cv2'\n",
    "WANDB_PROJECT_NAME = 'cv_competition_semi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "img_size = 380\n",
    "LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "\n",
    "patience = 5\n",
    "min_delta = 0.001 # 성능 개선의 최소 변화량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40496 3140\n"
     ]
    }
   ],
   "source": [
    "# test image 변환\n",
    "data_transform = A.Compose([\n",
    "    A.Resize(height = img_size, width = img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image = img)['image']\n",
    "    \n",
    "        return img, target\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.df[:, 1] \n",
    "\n",
    "trn_dataset = ImageDataset(\n",
    "    TRAIN_AUG_CSV_PATH,\n",
    "    TRAIN_AUG_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "val_dataset = ImageDataset(\n",
    "    VALID_CSV_PATH,\n",
    "    VALID_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    TEST_CSV_PATH,\n",
    "    TEST_IMAGE_PATH,\n",
    "    transform = data_transform\n",
    ")\n",
    "\n",
    "labels = trn_dataset.get_labels()\n",
    "labels = labels.astype(int)\n",
    "\n",
    "# DataLoader\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory = True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True,\n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b4.ra2_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b4.ra2_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (classifier.weight, classifier.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = timm.create_model('efficientnet_b4',\n",
    "                        pretrained=True,\n",
    "                        num_classes = 17).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(loader, model, loss_fn, device, epoch):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "\n",
    "    preds_list =[]\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader)\n",
    "        for step, (image, targets) in enumerate(pbar):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "       \n",
    "            valid_loss += loss.item()\n",
    "        \n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"valid_step\" : epoch * len(loader) + step,\n",
    "                \"valid_loss_step\" : loss.item()\n",
    "            })\n",
    "\n",
    "    valid_loss /= len(loader)\n",
    "    valid_acc = accuracy_score(targets_list, preds_list)\n",
    "    valid_f1 = f1_score(targets_list, preds_list, average = 'macro')\n",
    "\n",
    "    ret = {\n",
    "        \"epoch\" : epoch,\n",
    "        \"valid_loss\" : valid_loss,\n",
    "        \"valid_acc\" : valid_acc,\n",
    "        \"valid_f1\" : valid_f1\n",
    "    }\n",
    "\n",
    "    wandb.log({\n",
    "        \"valid_epoch\" : epoch,\n",
    "        \"val_loss_epoch\" : valid_loss,\n",
    "        \"val_acc\" : valid_acc,\n",
    "        \"val_f1\" : valid_f1\n",
    "    })\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습\n",
    "def train_one_epoch(train_loader, model, optimizer, loss_fn, device, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list =[]\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(train_loader)\n",
    "    for step, (image, targets) in enumerate(pbar):\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none = True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"train_step\" : epoch * len(train_loader) + step,\n",
    "            \"train_loss_step\" : loss.item()\n",
    "        })\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average = 'macro')\n",
    "\n",
    "    ret = {\n",
    "        \"model\" : model,\n",
    "        \"train_epoch\" : epoch,\n",
    "        \"train_loss\" : train_loss,\n",
    "        \"tarin_acc\" : train_acc,\n",
    "        \"train_f1\" : train_f1\n",
    "    }\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_epoch\" : epoch,\n",
    "        \"train_loss_epoch\" : train_loss,\n",
    "        \"train_acc\" : train_acc,\n",
    "        \"train_f1\" : train_f1\n",
    "    })\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0251: 100%|██████████| 1266/1266 [08:26<00:00,  2.50it/s]\n",
      "Loss: 1.4989: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.6769072085618972\n",
      "valid f1 : 0.8611162384987276\n",
      "성능 개선 됨 : 0.6769072085618972 > 0.999\n",
      "1 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0031: 100%|██████████| 1266/1266 [08:14<00:00,  2.56it/s]\n",
      "Loss: 0.5587: 100%|██████████| 10/10 [00:01<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.6164202451705932\n",
      "valid f1 : 0.8856442364645695\n",
      "성능 개선 됨 : 0.6164202451705932 > 0.6759072085618972\n",
      "2 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1831: 100%|██████████| 1266/1266 [08:13<00:00,  2.56it/s]\n",
      "Loss: 0.2157: 100%|██████████| 10/10 [00:01<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.8780327469110489\n",
      "valid f1 : 0.8508578487865732\n",
      "성능 개선 안됨 : 0.8780327469110489 > 0.6154202451705932\n",
      "patience counter : 1\n",
      "3 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0526: 100%|██████████| 1266/1266 [08:15<00:00,  2.56it/s]\n",
      "Loss: 0.7039: 100%|██████████| 10/10 [00:01<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.9044934295117855\n",
      "valid f1 : 0.8522657434391402\n",
      "성능 개선 안됨 : 0.9044934295117855 > 0.6154202451705932\n",
      "patience counter : 2\n",
      "4 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0213: 100%|██████████| 1266/1266 [08:15<00:00,  2.55it/s]\n",
      "Loss: 1.4972: 100%|██████████| 10/10 [00:01<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.9034376919269562\n",
      "valid f1 : 0.8588353796400221\n",
      "성능 개선 안됨 : 0.9034376919269562 > 0.6154202451705932\n",
      "patience counter : 3\n",
      "5 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0190: 100%|██████████| 1266/1266 [08:15<00:00,  2.55it/s]\n",
      "Loss: 0.7089: 100%|██████████| 10/10 [00:01<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.7906051486730575\n",
      "valid f1 : 0.8903422064879682\n",
      "성능 개선 안됨 : 0.7906051486730575 > 0.6154202451705932\n",
      "patience counter : 4\n",
      "6 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1226: 100%|██████████| 1266/1266 [08:14<00:00,  2.56it/s]\n",
      "Loss: 0.7403: 100%|██████████| 10/10 [00:01<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss : 0.8018599331378937\n",
      "valid f1 : 0.8999489216450755\n",
      "성능 개선 안됨 : 0.8018599331378937 > 0.6154202451705932\n",
      "patience counter : 5\n",
      "Early stopping at epoch 6\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "\n",
    "f1_scores = []\n",
    "valid_losses = []\n",
    "trained_models = []\n",
    "patience_counter = 0\n",
    "best_loss = 1\n",
    "\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT_NAME, name=\"effi_b0\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"{epoch} epoch\")\n",
    "    trn_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, epoch)\n",
    "    val_ret =  valid_one_epoch(val_loader, model, loss_fn, device, epoch)\n",
    "\n",
    "    f1_scores.append(val_ret['valid_f1'])\n",
    "    valid_losses.append(val_ret['valid_loss'])\n",
    "    trained_models.append(trn_ret['model'])\n",
    "\n",
    "    print(f\"valid loss : {val_ret['valid_loss']}\")\n",
    "    print(f\"valid f1 : {val_ret['valid_f1']}\")\n",
    "\n",
    "    # 성능 개선 됨\n",
    "    if val_ret['valid_loss'] < best_loss - min_delta:\n",
    "        print(f\"성능 개선 됨 : {val_ret['valid_loss']} > {best_loss - min_delta}\")\n",
    "        best_loss = val_ret['valid_loss']\n",
    "        patience_counter = 0  \n",
    "        \n",
    "    # 성능 개선 되지 않음\n",
    "    else:\n",
    "        patience_counter += 1  \n",
    "        print(f\"성능 개선 안됨 : {val_ret['valid_loss']} > {best_loss - min_delta}\")\n",
    "        print(f\"patience counter : {patience_counter}\")\n",
    "\n",
    "    # 성능 개선이 patience 만큼 안되면 학습 중단\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "best_model_idx = np.argmax(np.array(f1_scores))\n",
    "best_model = trained_models[best_model_idx]\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:15<00:00,  6.25it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = best_model(image)\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(f\"{RESULT_CSV_PATH}/semi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), '/upstage-cv-classification-cv2/results/effi_b4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
